2022-09-19 21:36:44,112 - INFO] DVC training
2022-09-19 21:36:44,113 - INFO] config : 
2022-09-19 21:36:44,115 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-19 21:38:19,505 - INFO] DVC training
2022-09-19 21:38:19,505 - INFO] config : 
2022-09-19 21:38:19,506 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-19 21:38:58,584 - INFO] DVC training
2022-09-19 21:38:58,584 - INFO] config : 
2022-09-19 21:38:58,585 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-19 21:41:53,062 - INFO] DVC training
2022-09-19 21:41:53,062 - INFO] config : 
2022-09-19 21:41:53,063 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-19 21:42:51,936 - INFO] DVC training
2022-09-19 21:42:51,936 - INFO] config : 
2022-09-19 21:42:51,938 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 20:43:20,427 - INFO] DVC training
2022-09-20 20:43:20,428 - INFO] config : 
2022-09-20 20:43:20,429 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 20:43:58,355 - INFO] DVC training
2022-09-20 20:43:58,355 - INFO] config : 
2022-09-20 20:43:58,363 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 20:54:07,047 - INFO] DVC training
2022-09-20 20:54:07,048 - INFO] config : 
2022-09-20 20:54:07,055 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 20:54:46,683 - INFO] DVC training
2022-09-20 20:54:46,683 - INFO] config : 
2022-09-20 20:54:46,694 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 20:55:54,139 - INFO] DVC training
2022-09-20 20:55:54,139 - INFO] config : 
2022-09-20 20:55:54,145 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 20:56:39,544 - INFO] DVC training
2022-09-20 20:56:39,544 - INFO] config : 
2022-09-20 20:56:39,551 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:03:13,489 - INFO] DVC training
2022-09-20 21:03:13,489 - INFO] config : 
2022-09-20 21:03:13,496 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:03:54,163 - INFO] DVC training
2022-09-20 21:03:54,163 - INFO] config : 
2022-09-20 21:03:54,164 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:05:13,848 - INFO] DVC training
2022-09-20 21:05:13,848 - INFO] config : 
2022-09-20 21:05:13,853 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:06:29,653 - INFO] DVC training
2022-09-20 21:06:29,654 - INFO] config : 
2022-09-20 21:06:29,655 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:08:16,051 - INFO] global step 0 : 

2022-09-20 21:08:16,052 - INFO] EWAP_eth dataset : average bpp : 0.129236, average psnr : 45.061000, average msssim: 0.995804

2022-09-20 21:11:21,106 - INFO] DVC training
2022-09-20 21:11:21,106 - INFO] config : 
2022-09-20 21:11:21,115 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:13:35,991 - INFO] DVC training
2022-09-20 21:13:35,991 - INFO] config : 
2022-09-20 21:13:35,998 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:14:47,862 - INFO] global step 0 : 

2022-09-20 21:14:47,863 - INFO] EWAP_eth dataset : average bpp : 0.109813, average psnr : 42.840489, average msssim: 0.993361

2022-09-20 21:36:21,971 - INFO] DVC training
2022-09-20 21:36:21,972 - INFO] config : 
2022-09-20 21:36:21,973 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:37:09,438 - INFO] DVC training
2022-09-20 21:37:09,439 - INFO] config : 
2022-09-20 21:37:09,444 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:38:30,049 - INFO] DVC training
2022-09-20 21:38:30,050 - INFO] config : 
2022-09-20 21:38:30,056 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:39:44,251 - INFO] DVC training
2022-09-20 21:39:44,252 - INFO] config : 
2022-09-20 21:39:44,253 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:40:52,003 - INFO] DVC training
2022-09-20 21:40:52,003 - INFO] config : 
2022-09-20 21:40:52,005 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:41:53,899 - INFO] DVC training
2022-09-20 21:41:53,900 - INFO] config : 
2022-09-20 21:41:53,900 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:43:23,028 - INFO] global step 0 : 

2022-09-20 21:43:23,029 - INFO] EWAP_eth dataset : average bpp : 0.081795, average psnr : 42.840451, average msssim: 0.993361

2022-09-20 21:43:51,437 - INFO] DVC training
2022-09-20 21:43:51,437 - INFO] config : 
2022-09-20 21:43:51,438 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:51:58,130 - INFO] global step 0 : 

2022-09-20 21:51:58,131 - INFO] EWAP_eth dataset : average bpp : 0.081259, average psnr : 42.772479, average msssim: 0.993742

2022-09-20 21:56:20,591 - INFO] DVC training
2022-09-20 21:56:20,591 - INFO] config : 
2022-09-20 21:56:20,597 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 21:57:19,946 - INFO] DVC training
2022-09-20 21:57:19,946 - INFO] config : 
2022-09-20 21:57:19,956 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:11:51,351 - INFO] global step 0 : 

2022-09-20 22:11:51,351 - INFO] EWAP_eth dataset : average bpp : 0.109621, average psnr : 40.440329, average msssim: 0.988293

2022-09-20 22:16:53,993 - INFO] DVC training
2022-09-20 22:16:53,994 - INFO] config : 
2022-09-20 22:16:53,995 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:17:43,993 - INFO] DVC training
2022-09-20 22:17:43,993 - INFO] config : 
2022-09-20 22:17:43,999 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:22:44,754 - INFO] DVC training
2022-09-20 22:22:44,754 - INFO] config : 
2022-09-20 22:22:44,760 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:23:13,398 - INFO] DVC training
2022-09-20 22:23:13,398 - INFO] config : 
2022-09-20 22:23:13,405 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:24:07,386 - INFO] DVC training
2022-09-20 22:24:07,386 - INFO] config : 
2022-09-20 22:24:07,394 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:24:31,532 - INFO] DVC training
2022-09-20 22:24:31,532 - INFO] config : 
2022-09-20 22:24:31,533 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:25:03,556 - INFO] DVC training
2022-09-20 22:25:03,557 - INFO] config : 
2022-09-20 22:25:03,563 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:26:05,982 - INFO] DVC training
2022-09-20 22:26:05,982 - INFO] config : 
2022-09-20 22:26:05,988 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:27:49,123 - INFO] global step 0 : 

2022-09-20 22:27:49,123 - INFO] EWAP_eth dataset : average bpp : 0.091750, average psnr : 34.741439, average msssim: 0.981631

2022-09-20 22:29:41,246 - INFO] DVC training
2022-09-20 22:29:41,247 - INFO] config : 
2022-09-20 22:29:41,255 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:31:32,330 - INFO] global step 0 : 

2022-09-20 22:31:32,331 - INFO] EWAP_eth dataset : average bpp : 0.090830, average psnr : 34.974513, average msssim: 0.982177

2022-09-20 22:32:28,744 - INFO] DVC training
2022-09-20 22:32:28,745 - INFO] config : 
2022-09-20 22:32:28,751 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:34:22,729 - INFO] DVC training
2022-09-20 22:34:22,729 - INFO] config : 
2022-09-20 22:34:22,740 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:39:11,862 - INFO] DVC training
2022-09-20 22:39:11,863 - INFO] config : 
2022-09-20 22:39:11,870 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:46:32,137 - INFO] global step 0 : 

2022-09-20 22:46:32,138 - INFO] EWAP_eth dataset : average bpp : 0.081497, average psnr : 35.601237, average msssim: 0.989701

2022-09-20 22:53:15,979 - INFO] DVC training
2022-09-20 22:53:15,979 - INFO] config : 
2022-09-20 22:53:15,986 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:53:48,043 - INFO] DVC training
2022-09-20 22:53:48,044 - INFO] config : 
2022-09-20 22:53:48,050 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:54:36,001 - INFO] DVC training
2022-09-20 22:54:36,002 - INFO] config : 
2022-09-20 22:54:36,008 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:56:13,354 - INFO] DVC training
2022-09-20 22:56:13,354 - INFO] config : 
2022-09-20 22:56:13,360 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 22:56:58,044 - INFO] DVC training
2022-09-20 22:56:58,045 - INFO] config : 
2022-09-20 22:56:58,050 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:03:41,188 - INFO] DVC training
2022-09-20 23:03:41,188 - INFO] config : 
2022-09-20 23:03:41,189 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:04:24,246 - INFO] DVC training
2022-09-20 23:04:24,246 - INFO] config : 
2022-09-20 23:04:24,253 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:05:21,392 - INFO] DVC training
2022-09-20 23:05:21,392 - INFO] config : 
2022-09-20 23:05:21,400 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:05:46,645 - INFO] DVC training
2022-09-20 23:05:46,646 - INFO] config : 
2022-09-20 23:05:46,647 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:07:09,266 - INFO] DVC training
2022-09-20 23:07:09,266 - INFO] config : 
2022-09-20 23:07:09,267 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:08:55,403 - INFO] DVC training
2022-09-20 23:08:55,403 - INFO] config : 
2022-09-20 23:08:55,410 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:10:35,632 - INFO] DVC training
2022-09-20 23:10:35,632 - INFO] config : 
2022-09-20 23:10:35,633 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:24:31,938 - INFO] Train Epoch : 00 Loss:	 0.162973	 lr:0.0001
2022-09-20 23:25:04,226 - INFO] DVC training
2022-09-20 23:25:04,226 - INFO] config : 
2022-09-20 23:25:04,235 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:32:02,573 - INFO] DVC training
2022-09-20 23:32:02,573 - INFO] config : 
2022-09-20 23:32:02,575 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:32:23,925 - INFO] global step 2093 : 

2022-09-20 23:32:23,926 - INFO] EWAP_eth dataset : average bpp : 1.344376, average psnr : 27.499631, average msssim: 0.944598

2022-09-20 23:32:48,412 - INFO] DVC training
2022-09-20 23:32:48,413 - INFO] config : 
2022-09-20 23:32:48,419 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:34:09,523 - INFO] global step 2093 : 

2022-09-20 23:34:09,524 - INFO] EWAP_eth dataset : average bpp : 1.345971, average psnr : 27.590475, average msssim: 0.940526

2022-09-20 23:46:14,276 - INFO] Train Epoch : 00 Loss:	 0.010796	 lr:0.0001
2022-09-20 23:46:48,961 - INFO] DVC training
2022-09-20 23:46:48,961 - INFO] config : 
2022-09-20 23:46:48,969 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-20 23:47:55,402 - INFO] global step 2093 : 

2022-09-20 23:47:55,403 - INFO] EWAP_eth dataset : average bpp : 0.074109, average psnr : 36.250043, average msssim: 0.989385

2022-09-21 00:00:03,370 - INFO] Train Epoch : 01 Loss:	 0.012046	 lr:0.0001
2022-09-21 00:14:00,091 - INFO] Train Epoch : 02 Loss:	 0.013176	 lr:0.0001
2022-09-21 00:27:46,894 - INFO] Train Epoch : 03 Loss:	 0.015758	 lr:0.0001
2022-09-21 00:41:44,871 - INFO] Train Epoch : 04 Loss:	 0.014145	 lr:0.0001
2022-09-21 00:55:40,620 - INFO] Train Epoch : 05 Loss:	 0.010064	 lr:0.0001
2022-09-21 01:09:33,711 - INFO] Train Epoch : 06 Loss:	 0.012732	 lr:0.0001
2022-09-21 01:23:30,998 - INFO] Train Epoch : 07 Loss:	 0.010810	 lr:0.0001
2022-09-21 01:37:16,408 - INFO] Train Epoch : 08 Loss:	 0.010425	 lr:0.0001
2022-09-21 01:51:15,065 - INFO] Train Epoch : 09 Loss:	 0.014778	 lr:0.0001
2022-09-21 02:05:05,958 - INFO] Train Epoch : 10 Loss:	 0.010575	 lr:0.0001
2022-09-21 02:19:00,926 - INFO] Train Epoch : 11 Loss:	 0.010415	 lr:0.0001
2022-09-21 02:33:00,787 - INFO] Train Epoch : 12 Loss:	 0.009999	 lr:0.0001
2022-09-21 02:46:49,964 - INFO] Train Epoch : 13 Loss:	 0.012827	 lr:0.0001
2022-09-21 03:00:45,679 - INFO] Train Epoch : 14 Loss:	 0.013274	 lr:0.0001
2022-09-21 03:14:34,377 - INFO] Train Epoch : 15 Loss:	 0.014505	 lr:0.0001
2022-09-21 03:28:32,831 - INFO] Train Epoch : 16 Loss:	 0.011515	 lr:0.0001
2022-09-21 03:42:31,514 - INFO] Train Epoch : 17 Loss:	 0.010667	 lr:0.0001
2022-09-21 03:56:17,166 - INFO] Train Epoch : 18 Loss:	 0.010176	 lr:0.0001
2022-09-21 04:10:14,976 - INFO] Train Epoch : 19 Loss:	 0.013318	 lr:0.0001
2022-09-21 04:24:01,365 - INFO] Train Epoch : 20 Loss:	 0.009547	 lr:0.0001
2022-09-21 04:38:01,125 - INFO] Train Epoch : 21 Loss:	 0.009344	 lr:0.0001
2022-09-21 04:51:58,162 - INFO] Train Epoch : 22 Loss:	 0.011659	 lr:0.0001
2022-09-21 05:05:46,075 - INFO] Train Epoch : 23 Loss:	 0.011170	 lr:0.0001
2022-09-21 05:19:44,266 - INFO] Train Epoch : 24 Loss:	 0.011059	 lr:0.0001
2022-09-21 05:33:30,704 - INFO] Train Epoch : 25 Loss:	 0.011766	 lr:0.0001
2022-09-21 05:47:27,223 - INFO] Train Epoch : 26 Loss:	 0.013090	 lr:0.0001
2022-09-21 06:01:26,484 - INFO] Train Epoch : 27 Loss:	 0.009649	 lr:0.0001
2022-09-21 06:15:12,286 - INFO] Train Epoch : 28 Loss:	 0.011082	 lr:0.0001
2022-09-21 06:29:09,031 - INFO] Train Epoch : 29 Loss:	 0.012273	 lr:0.0001
2022-09-21 06:42:53,095 - INFO] Train Epoch : 30 Loss:	 0.012937	 lr:0.0001
2022-09-21 06:56:48,162 - INFO] Train Epoch : 31 Loss:	 0.011902	 lr:0.0001
2022-09-21 07:10:39,578 - INFO] Train Epoch : 32 Loss:	 0.010191	 lr:0.0001
2022-09-21 07:24:32,693 - INFO] Train Epoch : 33 Loss:	 0.008351	 lr:0.0001
2022-09-21 07:38:30,861 - INFO] Train Epoch : 34 Loss:	 0.014124	 lr:0.0001
2022-09-21 07:52:17,170 - INFO] Train Epoch : 35 Loss:	 0.010950	 lr:0.0001
2022-09-21 08:06:13,834 - INFO] Train Epoch : 36 Loss:	 0.011937	 lr:0.0001
2022-09-21 08:20:04,957 - INFO] Train Epoch : 37 Loss:	 0.013418	 lr:0.0001
2022-09-21 08:33:57,008 - INFO] Train Epoch : 38 Loss:	 0.010052	 lr:0.0001
2022-09-21 08:47:56,268 - INFO] Train Epoch : 39 Loss:	 0.011842	 lr:0.0001
2022-09-21 09:01:42,805 - INFO] Train Epoch : 40 Loss:	 0.016703	 lr:0.0001
2022-09-21 09:12:34,407 - INFO] DVC training
2022-09-21 09:12:34,407 - INFO] config : 
2022-09-21 09:12:34,409 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-21 09:13:52,657 - INFO] global step 85813 : 

2022-09-21 09:13:52,658 - INFO] EWAP_eth dataset : average bpp : 0.066809, average psnr : 36.118877, average msssim: 0.989037

2022-09-21 09:15:38,256 - INFO] Train Epoch : 41 Loss:	 0.012968	 lr:0.0001
2022-09-21 09:29:02,556 - INFO] Train Epoch : 42 Loss:	 0.011686	 lr:0.0001
2022-09-21 09:39:27,795 - INFO] Train Epoch : 43 Loss:	 0.011731	 lr:0.0001
2022-09-21 09:48:27,316 - INFO] Train Epoch : 44 Loss:	 0.009568	 lr:0.0001
2022-09-21 09:53:41,360 - INFO] Train Epoch : 45 Loss:	 0.010889	 lr:0.0001
2022-09-21 09:58:58,209 - INFO] Train Epoch : 46 Loss:	 0.010929	 lr:0.0001
2022-09-21 10:04:15,405 - INFO] Train Epoch : 47 Loss:	 0.012563	 lr:0.0001
2022-09-21 10:09:39,137 - INFO] Train Epoch : 48 Loss:	 0.011616	 lr:0.0001
2022-09-21 10:14:57,797 - INFO] Train Epoch : 49 Loss:	 0.014430	 lr:0.0001
2022-09-21 10:20:37,941 - INFO] Train Epoch : 50 Loss:	 0.012529	 lr:0.0001
2022-09-21 10:26:09,504 - INFO] Train Epoch : 51 Loss:	 0.010576	 lr:0.0001
2022-09-21 10:31:50,941 - INFO] Train Epoch : 52 Loss:	 0.011506	 lr:0.0001
2022-09-21 10:37:48,656 - INFO] Train Epoch : 53 Loss:	 0.010281	 lr:0.0001
2022-09-21 10:43:04,538 - INFO] Train Epoch : 54 Loss:	 0.010987	 lr:0.0001
2022-09-21 10:48:21,554 - INFO] Train Epoch : 55 Loss:	 0.009675	 lr:0.0001
2022-09-21 10:54:19,713 - INFO] Train Epoch : 56 Loss:	 0.010913	 lr:0.0001
2022-09-21 11:01:38,904 - INFO] Train Epoch : 57 Loss:	 0.015129	 lr:0.0001
2022-09-21 11:06:56,502 - INFO] Train Epoch : 58 Loss:	 0.013168	 lr:0.0001
2022-09-21 11:12:12,423 - INFO] Train Epoch : 59 Loss:	 0.014033	 lr:0.0001
2022-09-21 11:17:27,396 - INFO] Train Epoch : 60 Loss:	 0.012419	 lr:0.0001
2022-09-21 11:22:41,044 - INFO] Train Epoch : 61 Loss:	 0.012113	 lr:0.0001
2022-09-21 11:28:01,545 - INFO] Train Epoch : 62 Loss:	 0.015378	 lr:0.0001
2022-09-21 11:33:46,137 - INFO] Train Epoch : 63 Loss:	 0.010717	 lr:0.0001
2022-09-21 11:39:23,885 - INFO] Train Epoch : 64 Loss:	 0.012606	 lr:0.0001
2022-09-21 11:44:57,384 - INFO] Train Epoch : 65 Loss:	 0.009706	 lr:0.0001
2022-09-21 11:50:13,531 - INFO] Train Epoch : 66 Loss:	 0.012030	 lr:0.0001
2022-09-21 11:55:30,292 - INFO] Train Epoch : 67 Loss:	 0.010157	 lr:0.0001
2022-09-21 12:00:43,853 - INFO] Train Epoch : 68 Loss:	 0.010426	 lr:0.0001
2022-09-21 12:05:58,543 - INFO] Train Epoch : 69 Loss:	 0.013492	 lr:0.0001
2022-09-21 12:11:13,300 - INFO] Train Epoch : 70 Loss:	 0.012862	 lr:0.0001
2022-09-21 12:16:27,403 - INFO] Train Epoch : 71 Loss:	 0.011214	 lr:0.0001
2022-09-21 12:21:42,417 - INFO] Train Epoch : 72 Loss:	 0.007557	 lr:0.0001
2022-09-21 12:27:01,256 - INFO] Train Epoch : 73 Loss:	 0.013228	 lr:0.0001
2022-09-21 12:32:18,474 - INFO] Train Epoch : 74 Loss:	 0.009201	 lr:0.0001
2022-09-21 12:37:32,262 - INFO] Train Epoch : 75 Loss:	 0.008828	 lr:0.0001
2022-09-21 12:42:47,229 - INFO] Train Epoch : 76 Loss:	 0.011688	 lr:0.0001
2022-09-21 12:48:02,517 - INFO] Train Epoch : 77 Loss:	 0.010881	 lr:0.0001
2022-09-21 12:53:16,657 - INFO] Train Epoch : 78 Loss:	 0.010706	 lr:0.0001
2022-09-21 12:58:34,458 - INFO] Train Epoch : 79 Loss:	 0.015593	 lr:0.0001
2022-09-21 13:03:54,095 - INFO] Train Epoch : 80 Loss:	 0.008991	 lr:0.0001
2022-09-21 13:09:08,984 - INFO] Train Epoch : 81 Loss:	 0.009508	 lr:0.0001
2022-09-21 13:14:30,600 - INFO] Train Epoch : 82 Loss:	 0.013053	 lr:0.0001
2022-09-21 13:19:46,959 - INFO] Train Epoch : 83 Loss:	 0.010443	 lr:0.0001
2022-09-21 13:25:01,973 - INFO] Train Epoch : 84 Loss:	 0.011645	 lr:0.0001
2022-09-21 13:30:19,522 - INFO] Train Epoch : 85 Loss:	 0.014051	 lr:0.0001
2022-09-21 13:35:37,297 - INFO] Train Epoch : 86 Loss:	 0.011359	 lr:0.0001
2022-09-21 13:41:09,228 - INFO] Train Epoch : 87 Loss:	 0.010371	 lr:0.0001
2022-09-21 13:46:48,219 - INFO] Train Epoch : 88 Loss:	 0.012060	 lr:0.0001
2022-09-21 13:52:25,096 - INFO] Train Epoch : 89 Loss:	 0.010262	 lr:0.0001
2022-09-21 13:58:24,609 - INFO] Train Epoch : 90 Loss:	 0.009014	 lr:0.0001
2022-09-21 14:03:40,745 - INFO] Train Epoch : 91 Loss:	 0.014103	 lr:0.0001
2022-09-21 14:08:56,260 - INFO] Train Epoch : 92 Loss:	 0.011419	 lr:0.0001
2022-09-21 14:14:15,562 - INFO] Train Epoch : 93 Loss:	 0.011082	 lr:0.0001
2022-09-21 14:19:30,177 - INFO] Train Epoch : 94 Loss:	 0.012851	 lr:0.0001
2022-09-21 14:24:48,849 - INFO] Train Epoch : 95 Loss:	 0.010990	 lr:0.0001
2022-09-21 14:30:08,731 - INFO] Train Epoch : 96 Loss:	 0.010265	 lr:0.0001
2022-09-21 14:35:25,528 - INFO] Train Epoch : 97 Loss:	 0.013319	 lr:0.0001
2022-09-21 14:40:42,975 - INFO] Train Epoch : 98 Loss:	 0.010278	 lr:0.0001
2022-09-21 14:45:59,944 - INFO] Train Epoch : 99 Loss:	 0.014853	 lr:0.0001
2022-09-21 14:51:18,151 - INFO] Train Epoch : 100 Loss:	 0.010023	 lr:0.0001
2022-09-21 14:56:34,832 - INFO] Train Epoch : 101 Loss:	 0.012258	 lr:0.0001
2022-09-21 15:01:49,947 - INFO] Train Epoch : 102 Loss:	 0.009727	 lr:0.0001
2022-09-21 15:07:04,680 - INFO] Train Epoch : 103 Loss:	 0.012744	 lr:0.0001
2022-09-21 15:12:21,053 - INFO] Train Epoch : 104 Loss:	 0.010175	 lr:0.0001
2022-09-21 15:17:39,732 - INFO] Train Epoch : 105 Loss:	 0.013087	 lr:0.0001
2022-09-21 15:23:07,710 - INFO] Train Epoch : 106 Loss:	 0.012898	 lr:0.0001
2022-09-21 15:28:38,246 - INFO] Train Epoch : 107 Loss:	 0.009278	 lr:0.0001
2022-09-21 15:34:17,649 - INFO] Train Epoch : 108 Loss:	 0.010143	 lr:0.0001
2022-09-21 15:39:36,119 - INFO] Train Epoch : 109 Loss:	 0.015092	 lr:0.0001
2022-09-21 15:44:52,236 - INFO] Train Epoch : 110 Loss:	 0.009380	 lr:0.0001
2022-09-21 15:50:06,523 - INFO] Train Epoch : 111 Loss:	 0.011530	 lr:0.0001
2022-09-21 15:55:22,296 - INFO] Train Epoch : 112 Loss:	 0.011647	 lr:0.0001
2022-09-21 16:00:37,306 - INFO] Train Epoch : 113 Loss:	 0.013000	 lr:0.0001
2022-09-21 16:05:51,296 - INFO] Train Epoch : 114 Loss:	 0.009393	 lr:0.0001
2022-09-21 16:11:05,053 - INFO] Train Epoch : 115 Loss:	 0.013837	 lr:0.0001
2022-09-21 16:16:26,878 - INFO] Train Epoch : 116 Loss:	 0.013011	 lr:0.0001
2022-09-21 16:21:47,736 - INFO] Train Epoch : 117 Loss:	 0.014232	 lr:0.0001
2022-09-21 16:27:05,234 - INFO] Train Epoch : 118 Loss:	 0.014207	 lr:0.0001
2022-09-21 16:32:22,468 - INFO] Train Epoch : 119 Loss:	 0.011841	 lr:0.0001
2022-09-21 16:37:38,573 - INFO] Train Epoch : 120 Loss:	 0.009530	 lr:0.0001
2022-09-21 16:42:56,548 - INFO] Train Epoch : 121 Loss:	 0.012432	 lr:0.0001
2022-09-21 16:48:52,289 - INFO] Train Epoch : 122 Loss:	 0.009797	 lr:0.0001
2022-09-21 16:55:21,144 - INFO] Train Epoch : 123 Loss:	 0.010923	 lr:0.0001
2022-09-21 17:00:18,910 - INFO] DVC training
2022-09-21 17:00:18,910 - INFO] config : 
2022-09-21 17:00:18,917 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 2000000,
    "train_lambda": 512,
    "lr": {
        "base": 0.0001,
        "decay": 0.1,
        "decay_interval": 1800000
    }
}

2022-09-21 17:01:06,422 - INFO] global step 259532 : 

2022-09-21 17:01:06,422 - INFO] EWAP_eth dataset : average bpp : 0.065311, average psnr : 35.965777, average msssim: 0.988553

2022-09-21 17:01:58,454 - INFO] Train Epoch : 124 Loss:	 0.010840	 lr:0.0001
2022-09-21 17:04:33,117 - INFO] DVC training
2022-09-21 17:04:33,117 - INFO] config : 
2022-09-21 17:04:33,118 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 17:10:28,634 - INFO] Train Epoch : 00 Loss:	 0.013582	 lr:1e-05
2022-09-21 17:11:47,550 - INFO] DVC training
2022-09-21 17:11:47,551 - INFO] config : 
2022-09-21 17:11:47,552 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 17:12:34,631 - INFO] global step 2093 : 

2022-09-21 17:12:34,631 - INFO] EWAP_eth dataset : average bpp : 0.078850, average psnr : 36.344371, average msssim: 0.989946

2022-09-21 17:16:53,555 - INFO] Train Epoch : 01 Loss:	 0.012762	 lr:1e-05
2022-09-21 17:22:14,308 - INFO] Train Epoch : 02 Loss:	 0.009447	 lr:1e-05
2022-09-21 17:27:39,400 - INFO] Train Epoch : 03 Loss:	 0.012630	 lr:1e-05
2022-09-21 17:33:05,135 - INFO] Train Epoch : 04 Loss:	 0.009926	 lr:1e-05
2022-09-21 17:38:32,324 - INFO] Train Epoch : 05 Loss:	 0.014058	 lr:1e-05
2022-09-21 17:44:00,028 - INFO] Train Epoch : 06 Loss:	 0.015864	 lr:1e-05
2022-09-21 17:49:27,118 - INFO] Train Epoch : 07 Loss:	 0.011320	 lr:1e-05
2022-09-21 17:54:54,428 - INFO] Train Epoch : 08 Loss:	 0.012374	 lr:1e-05
2022-09-21 18:00:15,422 - INFO] Train Epoch : 09 Loss:	 0.013788	 lr:1e-05
2022-09-21 18:05:32,673 - INFO] Train Epoch : 10 Loss:	 0.019526	 lr:1e-05
2022-09-21 18:10:48,166 - INFO] Train Epoch : 11 Loss:	 0.014438	 lr:1e-05
2022-09-21 18:16:03,040 - INFO] Train Epoch : 12 Loss:	 0.010210	 lr:1e-05
2022-09-21 18:21:18,315 - INFO] Train Epoch : 13 Loss:	 0.010191	 lr:1e-05
2022-09-21 18:26:35,450 - INFO] Train Epoch : 14 Loss:	 0.011862	 lr:1e-05
2022-09-21 18:31:49,284 - INFO] Train Epoch : 15 Loss:	 0.009003	 lr:1e-05
2022-09-21 18:37:05,474 - INFO] Train Epoch : 16 Loss:	 0.012800	 lr:1e-05
2022-09-21 18:42:22,520 - INFO] Train Epoch : 17 Loss:	 0.013021	 lr:1e-05
2022-09-21 18:47:40,848 - INFO] Train Epoch : 18 Loss:	 0.009538	 lr:1e-05
2022-09-21 18:54:03,480 - INFO] Train Epoch : 19 Loss:	 0.017875	 lr:1e-05
2022-09-21 18:59:54,676 - INFO] Train Epoch : 20 Loss:	 0.010920	 lr:1e-05
2022-09-21 19:06:30,389 - INFO] Train Epoch : 21 Loss:	 0.014173	 lr:1e-05
2022-09-21 19:13:00,882 - INFO] Train Epoch : 22 Loss:	 0.012661	 lr:1e-05
2022-09-21 19:19:33,315 - INFO] Train Epoch : 23 Loss:	 0.009879	 lr:1e-05
2022-09-21 19:25:42,717 - INFO] Train Epoch : 24 Loss:	 0.012062	 lr:1e-05
2022-09-21 19:28:00,628 - INFO] DVC training
2022-09-21 19:28:00,628 - INFO] config : 
2022-09-21 19:28:00,635 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:28:51,762 - INFO] global step 52325 : 

2022-09-21 19:28:51,762 - INFO] EWAP_eth dataset : average bpp : 0.069606, average psnr : 36.096364, average msssim: 0.989328

2022-09-21 19:31:07,313 - INFO] Train Epoch : 25 Loss:	 0.009935	 lr:1e-05
2022-09-21 19:36:24,808 - INFO] Train Epoch : 26 Loss:	 0.012107	 lr:1e-05
2022-09-21 19:41:41,532 - INFO] Train Epoch : 27 Loss:	 0.012536	 lr:1e-05
2022-09-21 19:44:08,053 - INFO] DVC training
2022-09-21 19:44:08,053 - INFO] config : 
2022-09-21 19:44:08,054 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:44:50,388 - INFO] DVC training
2022-09-21 19:44:50,389 - INFO] config : 
2022-09-21 19:44:50,396 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:45:40,085 - INFO] DVC training
2022-09-21 19:45:40,085 - INFO] config : 
2022-09-21 19:45:40,092 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:46:11,496 - INFO] DVC training
2022-09-21 19:46:11,496 - INFO] config : 
2022-09-21 19:46:11,504 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:47:10,938 - INFO] Train Epoch : 28 Loss:	 0.010401	 lr:1e-05
2022-09-21 19:48:25,601 - INFO] DVC training
2022-09-21 19:48:25,601 - INFO] config : 
2022-09-21 19:48:25,608 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:55:07,404 - INFO] DVC training
2022-09-21 19:55:07,405 - INFO] config : 
2022-09-21 19:55:07,406 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:55:34,855 - INFO] Train Epoch : 29 Loss:	 0.015075	 lr:1e-05
2022-09-21 19:57:00,397 - INFO] DVC training
2022-09-21 19:57:00,397 - INFO] config : 
2022-09-21 19:57:00,404 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:57:33,203 - INFO] DVC training
2022-09-21 19:57:33,203 - INFO] config : 
2022-09-21 19:57:33,205 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 19:58:21,699 - INFO] DVC training
2022-09-21 19:58:21,700 - INFO] config : 
2022-09-21 19:58:21,701 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:03:14,478 - INFO] Train Epoch : 30 Loss:	 0.009054	 lr:1e-05
2022-09-21 20:03:41,957 - INFO] DVC training
2022-09-21 20:03:41,957 - INFO] config : 
2022-09-21 20:03:41,964 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:05:05,273 - INFO] DVC training
2022-09-21 20:05:05,274 - INFO] config : 
2022-09-21 20:05:05,280 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:06:23,390 - INFO] DVC training
2022-09-21 20:06:23,390 - INFO] config : 
2022-09-21 20:06:23,397 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:07:41,009 - INFO] DVC training
2022-09-21 20:07:41,010 - INFO] config : 
2022-09-21 20:07:41,016 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:11:42,696 - INFO] Train Epoch : 31 Loss:	 0.011566	 lr:1e-05
2022-09-21 20:21:27,894 - INFO] Train Epoch : 32 Loss:	 0.011833	 lr:1e-05
2022-09-21 20:31:05,260 - INFO] Train Epoch : 33 Loss:	 0.009718	 lr:1e-05
2022-09-21 20:33:50,585 - INFO] DVC training
2022-09-21 20:33:50,585 - INFO] config : 
2022-09-21 20:33:50,591 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:34:16,836 - INFO] DVC training
2022-09-21 20:34:16,836 - INFO] config : 
2022-09-21 20:34:16,844 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:36:26,486 - INFO] DVC training
2022-09-21 20:36:26,486 - INFO] config : 
2022-09-21 20:36:26,488 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:36:45,768 - INFO] Train Epoch : 34 Loss:	 0.010671	 lr:1e-05
2022-09-21 20:38:38,436 - INFO] DVC training
2022-09-21 20:38:38,436 - INFO] config : 
2022-09-21 20:38:38,442 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:42:21,440 - INFO] Train Epoch : 35 Loss:	 0.012994	 lr:1e-05
2022-09-21 20:44:30,343 - INFO] DVC training
2022-09-21 20:44:30,343 - INFO] config : 
2022-09-21 20:44:30,350 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:47:45,170 - INFO] Train Epoch : 36 Loss:	 0.009345	 lr:1e-05
2022-09-21 20:49:13,440 - INFO] DVC training
2022-09-21 20:49:13,440 - INFO] config : 
2022-09-21 20:49:13,448 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:49:44,599 - INFO] DVC training
2022-09-21 20:49:44,599 - INFO] config : 
2022-09-21 20:49:44,600 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:50:22,689 - INFO] DVC training
2022-09-21 20:50:22,689 - INFO] config : 
2022-09-21 20:50:22,696 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 20:53:21,253 - INFO] Train Epoch : 37 Loss:	 0.011645	 lr:1e-05
2022-09-21 20:58:56,827 - INFO] Train Epoch : 38 Loss:	 0.015006	 lr:1e-05
2022-09-21 21:04:36,253 - INFO] Train Epoch : 39 Loss:	 0.011899	 lr:1e-05
2022-09-21 21:05:00,611 - INFO] DVC training
2022-09-21 21:05:00,611 - INFO] config : 
2022-09-21 21:05:00,613 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:06:28,867 - INFO] DVC training
2022-09-21 21:06:28,867 - INFO] config : 
2022-09-21 21:06:28,874 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:13:43,795 - INFO] Train Epoch : 40 Loss:	 0.012186	 lr:1e-05
2022-09-21 21:19:13,877 - INFO] Train Epoch : 00 Loss:	 0.010476	 lr:1e-05
2022-09-21 21:20:47,449 - INFO] DVC training
2022-09-21 21:20:47,449 - INFO] config : 
2022-09-21 21:20:47,451 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:21:36,797 - INFO] DVC training
2022-09-21 21:21:36,797 - INFO] config : 
2022-09-21 21:21:36,798 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:22:46,695 - INFO] global step 2093 : 

2022-09-21 21:22:46,696 - INFO] EWAP_eth dataset : average bpp : 0.077599, average psnr : 35.079471, average msssim: 0.981171

2022-09-21 21:23:29,366 - INFO] Train Epoch : 41 Loss:	 0.012058	 lr:1e-05
2022-09-21 21:31:50,236 - INFO] Train Epoch : 01 Loss:	 0.013367	 lr:1e-05
2022-09-21 21:33:14,992 - INFO] Train Epoch : 42 Loss:	 0.013229	 lr:1e-05
2022-09-21 21:40:15,546 - INFO] DVC training
2022-09-21 21:40:15,546 - INFO] config : 
2022-09-21 21:40:15,548 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:41:24,072 - INFO] global step 2093 : 

2022-09-21 21:41:24,073 - INFO] EWAP_eth dataset : average bpp : 0.077599, average psnr : 35.079448, average msssim: 0.981171

2022-09-21 21:41:39,202 - INFO] DVC training
2022-09-21 21:41:39,202 - INFO] config : 
2022-09-21 21:41:39,209 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:42:39,574 - INFO] DVC training
2022-09-21 21:42:39,574 - INFO] config : 
2022-09-21 21:42:39,580 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:43:03,784 - INFO] Train Epoch : 43 Loss:	 0.007446	 lr:1e-05
2022-09-21 21:43:50,125 - INFO] global step 4186 : 

2022-09-21 21:43:50,125 - INFO] EWAP_eth dataset : average bpp : 0.077009, average psnr : 35.131174, average msssim: 0.981100

2022-09-21 21:44:38,470 - INFO] DVC training
2022-09-21 21:44:38,470 - INFO] config : 
2022-09-21 21:44:38,478 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:46:35,813 - INFO] DVC training
2022-09-21 21:46:35,813 - INFO] config : 
2022-09-21 21:46:35,814 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:47:19,689 - INFO] DVC training
2022-09-21 21:47:19,690 - INFO] config : 
2022-09-21 21:47:19,696 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:50:19,594 - INFO] Train Epoch : 44 Loss:	 0.014187	 lr:1e-05
2022-09-21 21:54:06,775 - INFO] DVC training
2022-09-21 21:54:06,776 - INFO] config : 
2022-09-21 21:54:06,777 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-21 21:59:52,652 - INFO] Train Epoch : 45 Loss:	 0.014001	 lr:1e-05
2022-09-21 22:07:15,943 - INFO] Train Epoch : 00 Loss:	 0.607350	 lr:1e-05
2022-09-21 22:09:44,570 - INFO] Train Epoch : 46 Loss:	 0.013793	 lr:1e-05
2022-09-21 22:19:38,088 - INFO] Train Epoch : 47 Loss:	 0.010179	 lr:1e-05
2022-09-21 22:20:14,698 - INFO] Train Epoch : 01 Loss:	 0.478898	 lr:1e-05
2022-09-21 22:29:31,886 - INFO] Train Epoch : 48 Loss:	 0.011814	 lr:1e-05
2022-09-21 22:33:10,172 - INFO] Train Epoch : 02 Loss:	 0.392008	 lr:1e-05
2022-09-21 22:39:24,401 - INFO] Train Epoch : 49 Loss:	 0.015150	 lr:1e-05
2022-09-21 22:46:07,589 - INFO] Train Epoch : 03 Loss:	 0.307063	 lr:1e-05
2022-09-21 22:49:17,102 - INFO] Train Epoch : 50 Loss:	 0.010199	 lr:1e-05
2022-09-21 22:59:04,431 - INFO] Train Epoch : 04 Loss:	 0.244876	 lr:1e-05
2022-09-21 22:59:10,676 - INFO] Train Epoch : 51 Loss:	 0.010724	 lr:1e-05
2022-09-21 23:09:04,396 - INFO] Train Epoch : 52 Loss:	 0.015550	 lr:1e-05
2022-09-21 23:12:03,841 - INFO] Train Epoch : 05 Loss:	 0.232060	 lr:1e-05
2022-09-21 23:18:57,826 - INFO] Train Epoch : 53 Loss:	 0.011471	 lr:1e-05
2022-09-21 23:25:01,340 - INFO] Train Epoch : 06 Loss:	 0.234508	 lr:1e-05
2022-09-21 23:28:50,689 - INFO] Train Epoch : 54 Loss:	 0.009230	 lr:1e-05
2022-09-21 23:37:57,889 - INFO] Train Epoch : 07 Loss:	 0.185880	 lr:1e-05
2022-09-21 23:38:44,800 - INFO] Train Epoch : 55 Loss:	 0.010058	 lr:1e-05
2022-09-21 23:48:40,169 - INFO] Train Epoch : 56 Loss:	 0.010167	 lr:1e-05
2022-09-21 23:50:50,690 - INFO] Train Epoch : 08 Loss:	 0.169785	 lr:1e-05
2022-09-21 23:58:33,075 - INFO] Train Epoch : 57 Loss:	 0.010155	 lr:1e-05
2022-09-22 00:03:47,483 - INFO] Train Epoch : 09 Loss:	 0.184140	 lr:1e-05
2022-09-22 00:08:26,483 - INFO] Train Epoch : 58 Loss:	 0.009241	 lr:1e-05
2022-09-22 00:16:43,578 - INFO] Train Epoch : 10 Loss:	 0.145808	 lr:1e-05
2022-09-22 00:18:19,341 - INFO] Train Epoch : 59 Loss:	 0.010248	 lr:1e-05
2022-09-22 00:28:14,285 - INFO] Train Epoch : 60 Loss:	 0.011553	 lr:1e-05
2022-09-22 00:29:40,690 - INFO] Train Epoch : 11 Loss:	 0.145401	 lr:1e-05
2022-09-22 00:38:06,728 - INFO] Train Epoch : 61 Loss:	 0.012886	 lr:1e-05
2022-09-22 00:42:38,259 - INFO] Train Epoch : 12 Loss:	 0.134067	 lr:1e-05
2022-09-22 00:47:59,065 - INFO] Train Epoch : 62 Loss:	 0.014023	 lr:1e-05
2022-09-22 00:55:33,569 - INFO] Train Epoch : 13 Loss:	 0.118048	 lr:1e-05
2022-09-22 00:57:53,196 - INFO] Train Epoch : 63 Loss:	 0.010346	 lr:1e-05
2022-09-22 01:07:47,302 - INFO] Train Epoch : 64 Loss:	 0.012516	 lr:1e-05
2022-09-22 01:08:30,133 - INFO] Train Epoch : 14 Loss:	 0.119461	 lr:1e-05
2022-09-22 01:17:40,654 - INFO] Train Epoch : 65 Loss:	 0.013635	 lr:1e-05
2022-09-22 01:21:29,217 - INFO] Train Epoch : 15 Loss:	 0.109261	 lr:1e-05
2022-09-22 01:27:34,006 - INFO] Train Epoch : 66 Loss:	 0.009573	 lr:1e-05
2022-09-22 01:34:25,391 - INFO] Train Epoch : 16 Loss:	 0.122763	 lr:1e-05
2022-09-22 01:37:27,557 - INFO] Train Epoch : 67 Loss:	 0.012928	 lr:1e-05
2022-09-22 01:47:20,807 - INFO] Train Epoch : 17 Loss:	 0.105177	 lr:1e-05
2022-09-22 01:47:22,327 - INFO] Train Epoch : 68 Loss:	 0.008074	 lr:1e-05
2022-09-22 01:57:17,906 - INFO] Train Epoch : 69 Loss:	 0.012918	 lr:1e-05
2022-09-22 02:00:16,180 - INFO] Train Epoch : 18 Loss:	 0.089866	 lr:1e-05
2022-09-22 02:07:10,774 - INFO] Train Epoch : 70 Loss:	 0.010462	 lr:1e-05
2022-09-22 02:13:14,262 - INFO] Train Epoch : 19 Loss:	 0.108447	 lr:1e-05
2022-09-22 02:17:03,579 - INFO] Train Epoch : 71 Loss:	 0.011097	 lr:1e-05
2022-09-22 02:26:10,176 - INFO] Train Epoch : 20 Loss:	 0.087765	 lr:1e-05
2022-09-22 02:26:57,407 - INFO] Train Epoch : 72 Loss:	 0.010857	 lr:1.0000000000000002e-06
2022-09-22 02:36:54,542 - INFO] Train Epoch : 73 Loss:	 0.010494	 lr:1.0000000000000002e-06
2022-09-22 02:39:04,468 - INFO] Train Epoch : 21 Loss:	 0.094109	 lr:1e-05
2022-09-22 02:46:48,564 - INFO] Train Epoch : 74 Loss:	 0.010066	 lr:1.0000000000000002e-06
2022-09-22 02:51:59,437 - INFO] Train Epoch : 22 Loss:	 0.092114	 lr:1e-05
2022-09-22 02:56:41,784 - INFO] Train Epoch : 75 Loss:	 0.012080	 lr:1.0000000000000002e-06
2022-09-22 03:04:53,191 - INFO] Train Epoch : 23 Loss:	 0.090142	 lr:1e-05
2022-09-22 03:06:37,050 - INFO] Train Epoch : 76 Loss:	 0.013326	 lr:1.0000000000000002e-06
2022-09-22 03:16:29,549 - INFO] Train Epoch : 77 Loss:	 0.012587	 lr:1.0000000000000002e-06
2022-09-22 03:17:50,751 - INFO] Train Epoch : 24 Loss:	 0.079604	 lr:1e-05
2022-09-22 03:26:23,072 - INFO] Train Epoch : 78 Loss:	 0.011307	 lr:1.0000000000000002e-06
2022-09-22 03:30:46,718 - INFO] Train Epoch : 25 Loss:	 0.076390	 lr:1e-05
2022-09-22 03:36:16,040 - INFO] Train Epoch : 79 Loss:	 0.011236	 lr:1.0000000000000002e-06
2022-09-22 03:43:41,053 - INFO] Train Epoch : 26 Loss:	 0.091251	 lr:1e-05
2022-09-22 03:46:11,295 - INFO] Train Epoch : 80 Loss:	 0.010899	 lr:1.0000000000000002e-06
2022-09-22 03:56:05,581 - INFO] Train Epoch : 81 Loss:	 0.012306	 lr:1.0000000000000002e-06
2022-09-22 03:56:35,604 - INFO] Train Epoch : 27 Loss:	 0.079990	 lr:1e-05
2022-09-22 04:05:58,137 - INFO] Train Epoch : 82 Loss:	 0.009558	 lr:1.0000000000000002e-06
2022-09-22 04:09:32,374 - INFO] Train Epoch : 28 Loss:	 0.071063	 lr:1e-05
2022-09-22 04:15:52,344 - INFO] Train Epoch : 83 Loss:	 0.011595	 lr:1.0000000000000002e-06
2022-09-22 04:22:26,257 - INFO] Train Epoch : 29 Loss:	 0.080527	 lr:1e-05
2022-09-22 04:25:46,024 - INFO] Train Epoch : 84 Loss:	 0.012793	 lr:1.0000000000000002e-06
2022-09-22 04:35:23,142 - INFO] Train Epoch : 30 Loss:	 0.074690	 lr:1e-05
2022-09-22 04:35:40,989 - INFO] Train Epoch : 85 Loss:	 0.010688	 lr:1.0000000000000002e-06
2022-09-22 04:45:35,275 - INFO] Train Epoch : 86 Loss:	 0.009819	 lr:1.0000000000000002e-06
2022-09-22 04:48:18,294 - INFO] Train Epoch : 31 Loss:	 0.073503	 lr:1e-05
2022-09-22 04:55:30,074 - INFO] Train Epoch : 87 Loss:	 0.008179	 lr:1.0000000000000002e-06
2022-09-22 05:01:14,141 - INFO] Train Epoch : 32 Loss:	 0.066956	 lr:1e-05
2022-09-22 05:05:24,770 - INFO] Train Epoch : 88 Loss:	 0.008144	 lr:1.0000000000000002e-06
2022-09-22 05:14:11,674 - INFO] Train Epoch : 33 Loss:	 0.072144	 lr:1e-05
2022-09-22 05:15:18,460 - INFO] Train Epoch : 89 Loss:	 0.010886	 lr:1.0000000000000002e-06
2022-09-22 05:25:13,085 - INFO] Train Epoch : 90 Loss:	 0.012780	 lr:1.0000000000000002e-06
2022-09-22 05:27:04,984 - INFO] Train Epoch : 34 Loss:	 0.070167	 lr:1e-05
2022-09-22 05:35:08,895 - INFO] Train Epoch : 91 Loss:	 0.011625	 lr:1.0000000000000002e-06
2022-09-22 05:39:58,655 - INFO] Train Epoch : 35 Loss:	 0.068535	 lr:1e-05
2022-09-22 05:45:02,524 - INFO] Train Epoch : 92 Loss:	 0.012948	 lr:1.0000000000000002e-06
2022-09-22 05:52:53,360 - INFO] Train Epoch : 36 Loss:	 0.077002	 lr:1e-05
2022-09-22 05:54:57,004 - INFO] Train Epoch : 93 Loss:	 0.012146	 lr:1.0000000000000002e-06
2022-09-22 06:04:51,578 - INFO] Train Epoch : 94 Loss:	 0.009707	 lr:1.0000000000000002e-06
2022-09-22 06:05:49,734 - INFO] Train Epoch : 37 Loss:	 0.072406	 lr:1e-05
2022-09-22 06:14:44,812 - INFO] Train Epoch : 95 Loss:	 0.011297	 lr:1.0000000000000002e-06
2022-09-22 06:16:53,232 - INFO] Train Epoch : 38 Loss:	 0.058649	 lr:1e-05
2022-09-22 06:23:44,823 - INFO] Train Epoch : 39 Loss:	 0.071529	 lr:1e-05
2022-09-22 06:30:37,377 - INFO] Train Epoch : 40 Loss:	 0.067636	 lr:1e-05
2022-09-22 06:37:27,593 - INFO] Train Epoch : 41 Loss:	 0.068906	 lr:1e-05
2022-09-22 06:44:19,832 - INFO] Train Epoch : 42 Loss:	 0.068802	 lr:1e-05
2022-09-22 06:51:09,099 - INFO] Train Epoch : 43 Loss:	 0.069463	 lr:1e-05
2022-09-22 06:57:59,812 - INFO] Train Epoch : 44 Loss:	 0.061093	 lr:1e-05
2022-09-22 07:04:50,280 - INFO] Train Epoch : 45 Loss:	 0.069978	 lr:1e-05
2022-09-22 07:11:40,749 - INFO] Train Epoch : 46 Loss:	 0.073563	 lr:1e-05
2022-09-22 07:18:31,310 - INFO] Train Epoch : 47 Loss:	 0.062756	 lr:1e-05
2022-09-22 07:25:22,977 - INFO] Train Epoch : 48 Loss:	 0.066161	 lr:1e-05
2022-09-22 07:32:14,458 - INFO] Train Epoch : 49 Loss:	 0.069746	 lr:1e-05
2022-09-22 07:39:04,323 - INFO] Train Epoch : 50 Loss:	 0.057439	 lr:1e-05
2022-09-22 07:45:56,188 - INFO] Train Epoch : 51 Loss:	 0.054142	 lr:1e-05
2022-09-22 07:52:45,209 - INFO] Train Epoch : 52 Loss:	 0.062935	 lr:1e-05
2022-09-22 07:59:33,374 - INFO] Train Epoch : 53 Loss:	 0.060516	 lr:1e-05
2022-09-22 08:06:25,297 - INFO] Train Epoch : 54 Loss:	 0.067803	 lr:1e-05
2022-09-22 08:13:17,443 - INFO] Train Epoch : 55 Loss:	 0.068347	 lr:1e-05
2022-09-22 08:20:12,253 - INFO] Train Epoch : 56 Loss:	 0.073390	 lr:1e-05
2022-09-22 08:27:05,595 - INFO] Train Epoch : 57 Loss:	 0.057860	 lr:1e-05
2022-09-22 08:33:57,624 - INFO] Train Epoch : 58 Loss:	 0.067456	 lr:1e-05
2022-09-22 08:40:49,898 - INFO] Train Epoch : 59 Loss:	 0.065170	 lr:1e-05
2022-09-22 08:47:43,117 - INFO] Train Epoch : 60 Loss:	 0.064246	 lr:1e-05
2022-09-22 08:54:33,449 - INFO] Train Epoch : 61 Loss:	 0.063857	 lr:1e-05
2022-09-22 09:01:23,498 - INFO] Train Epoch : 62 Loss:	 0.064781	 lr:1e-05
2022-09-22 09:08:14,293 - INFO] Train Epoch : 63 Loss:	 0.057418	 lr:1e-05
2022-09-22 09:15:06,431 - INFO] Train Epoch : 64 Loss:	 0.063272	 lr:1e-05
2022-09-22 09:21:58,924 - INFO] Train Epoch : 65 Loss:	 0.054995	 lr:1e-05
2022-09-22 09:29:30,147 - INFO] DVC training
2022-09-22 09:29:30,148 - INFO] config : 
2022-09-22 09:29:30,149 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 09:31:08,900 - INFO] DVC training
2022-09-22 09:31:08,900 - INFO] config : 
2022-09-22 09:31:08,902 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 09:32:17,844 - INFO] global step 98371 : 

2022-09-22 09:32:17,845 - INFO] EWAP_eth dataset : average bpp : 0.072441, average psnr : 29.515561, average msssim: 0.961844

2022-09-22 10:32:07,788 - INFO] DVC training
2022-09-22 10:32:07,788 - INFO] config : 
2022-09-22 10:32:07,795 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 10:38:58,703 - INFO] Train Epoch : 00 Loss:	 0.011209	 lr:1e-05
2022-09-22 10:45:43,514 - INFO] Train Epoch : 01 Loss:	 0.011365	 lr:1e-05
2022-09-22 10:49:12,978 - INFO] DVC training
2022-09-22 10:49:12,979 - INFO] config : 
2022-09-22 10:49:12,980 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 10:50:21,970 - INFO] global step 2093 : 

2022-09-22 10:50:21,971 - INFO] EWAP_eth dataset : average bpp : 0.308234, average psnr : 30.788087, average msssim: 0.358110

2022-09-22 10:52:30,047 - INFO] Train Epoch : 02 Loss:	 0.008178	 lr:1e-05
2022-09-22 10:53:39,472 - INFO] DVC training
2022-09-22 10:53:39,472 - INFO] config : 
2022-09-22 10:53:39,479 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 10:54:56,911 - INFO] DVC training
2022-09-22 10:54:56,911 - INFO] config : 
2022-09-22 10:54:56,918 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 10:57:08,706 - INFO] DVC training
2022-09-22 10:57:08,706 - INFO] config : 
2022-09-22 10:57:08,707 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 10:58:17,823 - INFO] global step 2093 : 

2022-09-22 10:58:17,824 - INFO] EWAP_eth dataset : average bpp : 0.077509, average psnr : 38.785516, average msssim: 0.981115

2022-09-22 10:59:20,226 - INFO] Train Epoch : 03 Loss:	 0.007588	 lr:1e-05
2022-09-22 11:06:05,951 - INFO] Train Epoch : 04 Loss:	 0.009750	 lr:1e-05
2022-09-22 11:12:50,995 - INFO] Train Epoch : 05 Loss:	 0.010117	 lr:1e-05
2022-09-22 11:15:33,768 - INFO] DVC training
2022-09-22 11:15:33,768 - INFO] config : 
2022-09-22 11:15:33,776 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 11:16:37,608 - INFO] global step 2093 : 

2022-09-22 11:16:37,609 - INFO] EWAP_eth dataset : average bpp : 0.082383, average psnr : 38.854901, average msssim: 0.980398

2022-09-22 11:17:53,391 - INFO] DVC training
2022-09-22 11:17:53,391 - INFO] config : 
2022-09-22 11:17:53,393 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 11:19:15,863 - INFO] DVC training
2022-09-22 11:19:15,864 - INFO] config : 
2022-09-22 11:19:15,870 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 11:19:40,905 - INFO] Train Epoch : 06 Loss:	 0.011303	 lr:1e-05
2022-09-22 11:23:14,608 - INFO] DVC training
2022-09-22 11:23:14,608 - INFO] config : 
2022-09-22 11:23:14,614 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 11:24:23,296 - INFO] global step 2093 : 

2022-09-22 11:24:23,297 - INFO] EWAP_eth dataset : average bpp : 0.077510, average psnr : 38.785626, average msssim: 0.981115

2022-09-22 11:26:28,060 - INFO] Train Epoch : 07 Loss:	 0.009295	 lr:1e-05
2022-09-22 11:33:12,710 - INFO] Train Epoch : 08 Loss:	 0.009277	 lr:1e-05
2022-09-22 11:39:59,043 - INFO] Train Epoch : 09 Loss:	 0.008263	 lr:1e-05
2022-09-22 11:46:44,001 - INFO] Train Epoch : 10 Loss:	 0.008927	 lr:1e-05
2022-09-22 11:53:29,597 - INFO] Train Epoch : 11 Loss:	 0.008957	 lr:1e-05
2022-09-22 12:00:14,769 - INFO] Train Epoch : 12 Loss:	 0.009615	 lr:1e-05
2022-09-22 12:06:59,481 - INFO] Train Epoch : 13 Loss:	 0.009150	 lr:1e-05
2022-09-22 12:13:43,898 - INFO] Train Epoch : 14 Loss:	 0.007776	 lr:1e-05
2022-09-22 12:20:29,437 - INFO] Train Epoch : 15 Loss:	 0.007841	 lr:1e-05
2022-09-22 12:27:16,928 - INFO] Train Epoch : 16 Loss:	 0.009782	 lr:1e-05
2022-09-22 12:34:02,408 - INFO] Train Epoch : 17 Loss:	 0.009966	 lr:1e-05
2022-09-22 12:40:48,204 - INFO] Train Epoch : 18 Loss:	 0.009676	 lr:1e-05
2022-09-22 12:47:33,243 - INFO] Train Epoch : 19 Loss:	 0.008314	 lr:1e-05
2022-09-22 12:54:18,272 - INFO] Train Epoch : 20 Loss:	 0.009196	 lr:1e-05
2022-09-22 13:01:04,405 - INFO] Train Epoch : 21 Loss:	 0.008106	 lr:1e-05
2022-09-22 13:07:49,989 - INFO] Train Epoch : 22 Loss:	 0.009000	 lr:1e-05
2022-09-22 13:14:35,243 - INFO] Train Epoch : 23 Loss:	 0.009454	 lr:1e-05
2022-09-22 13:21:22,347 - INFO] Train Epoch : 24 Loss:	 0.009297	 lr:1e-05
2022-09-22 13:28:08,709 - INFO] Train Epoch : 25 Loss:	 0.008471	 lr:1e-05
2022-09-22 13:34:54,290 - INFO] Train Epoch : 26 Loss:	 0.008399	 lr:1e-05
2022-09-22 13:41:37,812 - INFO] Train Epoch : 27 Loss:	 0.008518	 lr:1e-05
2022-09-22 13:48:22,951 - INFO] Train Epoch : 28 Loss:	 0.007769	 lr:1e-05
2022-09-22 13:55:08,601 - INFO] Train Epoch : 29 Loss:	 0.009362	 lr:1e-05
2022-09-22 14:01:53,982 - INFO] Train Epoch : 30 Loss:	 0.009043	 lr:1e-05
2022-09-22 14:08:39,999 - INFO] Train Epoch : 31 Loss:	 0.006700	 lr:1e-05
2022-09-22 14:15:24,514 - INFO] Train Epoch : 32 Loss:	 0.010226	 lr:1e-05
2022-09-22 14:22:11,487 - INFO] Train Epoch : 33 Loss:	 0.008635	 lr:1e-05
2022-09-22 14:28:59,160 - INFO] Train Epoch : 34 Loss:	 0.009192	 lr:1e-05
2022-09-22 14:34:00,938 - INFO] DVC training
2022-09-22 14:34:00,938 - INFO] config : 
2022-09-22 14:34:00,939 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 14:40:55,173 - INFO] Train Epoch : 00 Loss:	 0.011541	 lr:1e-05
2022-09-22 14:47:39,431 - INFO] Train Epoch : 01 Loss:	 0.012874	 lr:1e-05
2022-09-22 14:48:18,766 - INFO] DVC training
2022-09-22 14:48:18,766 - INFO] config : 
2022-09-22 14:48:18,768 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 14:49:27,869 - INFO] global step 2093 : 

2022-09-22 14:49:27,870 - INFO] EWAP_eth dataset : average bpp : 0.077589, average psnr : 35.079255, average msssim: 0.981133

2022-09-22 14:50:24,069 - INFO] DVC training
2022-09-22 14:50:24,069 - INFO] config : 
2022-09-22 14:50:24,071 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-22 14:51:33,111 - INFO] global step 0 : 

2022-09-22 14:51:33,112 - INFO] EWAP_eth dataset : average bpp : 0.081392, average psnr : 34.041590, average msssim: 0.980230

2022-09-22 14:54:27,995 - INFO] Train Epoch : 02 Loss:	 0.012744	 lr:1e-05
2022-09-22 15:01:14,167 - INFO] Train Epoch : 03 Loss:	 0.011254	 lr:1e-05
2022-09-22 15:08:14,718 - INFO] Train Epoch : 04 Loss:	 0.015183	 lr:1e-05
2022-09-22 15:15:16,653 - INFO] Train Epoch : 05 Loss:	 0.014544	 lr:1e-05
2022-09-22 15:22:03,529 - INFO] Train Epoch : 06 Loss:	 0.014177	 lr:1e-05
2022-09-22 15:29:04,464 - INFO] Train Epoch : 07 Loss:	 0.010632	 lr:1e-05
2022-09-22 15:36:35,356 - INFO] Train Epoch : 08 Loss:	 0.012792	 lr:1e-05
2022-09-22 15:44:58,815 - INFO] Train Epoch : 09 Loss:	 0.011599	 lr:1e-05
2022-09-22 15:52:09,009 - INFO] Train Epoch : 10 Loss:	 0.009694	 lr:1e-05
2022-09-22 15:58:56,714 - INFO] Train Epoch : 11 Loss:	 0.013051	 lr:1e-05
2022-09-22 16:05:46,024 - INFO] Train Epoch : 12 Loss:	 0.015270	 lr:1e-05
2022-09-22 16:12:35,834 - INFO] Train Epoch : 13 Loss:	 0.009597	 lr:1e-05
2022-09-22 16:19:23,369 - INFO] Train Epoch : 14 Loss:	 0.011817	 lr:1e-05
2022-09-22 16:26:10,328 - INFO] Train Epoch : 15 Loss:	 0.013880	 lr:1e-05
2022-09-22 16:32:58,124 - INFO] Train Epoch : 16 Loss:	 0.012400	 lr:1e-05
2022-09-22 16:39:48,628 - INFO] Train Epoch : 17 Loss:	 0.014210	 lr:1e-05
2022-09-22 16:46:39,449 - INFO] Train Epoch : 18 Loss:	 0.013751	 lr:1e-05
2022-09-22 16:53:26,506 - INFO] Train Epoch : 19 Loss:	 0.012442	 lr:1e-05
2022-09-22 17:00:10,299 - INFO] Train Epoch : 20 Loss:	 0.010891	 lr:1e-05
2022-09-22 17:06:56,372 - INFO] Train Epoch : 21 Loss:	 0.010382	 lr:1e-05
2022-09-22 17:13:40,912 - INFO] Train Epoch : 22 Loss:	 0.015426	 lr:1e-05
2022-09-22 17:20:26,127 - INFO] Train Epoch : 23 Loss:	 0.011342	 lr:1e-05
2022-09-22 17:27:10,818 - INFO] Train Epoch : 24 Loss:	 0.009384	 lr:1e-05
2022-09-22 17:33:56,844 - INFO] Train Epoch : 25 Loss:	 0.008585	 lr:1e-05
2022-09-22 17:40:42,882 - INFO] Train Epoch : 26 Loss:	 0.013102	 lr:1e-05
2022-09-22 17:47:30,860 - INFO] Train Epoch : 27 Loss:	 0.011831	 lr:1e-05
2022-09-22 17:54:17,756 - INFO] Train Epoch : 28 Loss:	 0.013188	 lr:1e-05
2022-09-22 18:01:02,288 - INFO] Train Epoch : 29 Loss:	 0.009644	 lr:1e-05
2022-09-22 18:07:47,238 - INFO] Train Epoch : 30 Loss:	 0.011219	 lr:1e-05
2022-09-22 18:14:30,973 - INFO] Train Epoch : 31 Loss:	 0.012160	 lr:1e-05
2022-09-22 18:21:16,697 - INFO] Train Epoch : 32 Loss:	 0.014048	 lr:1e-05
2022-09-22 18:28:02,644 - INFO] Train Epoch : 33 Loss:	 0.011574	 lr:1e-05
2022-09-22 18:34:49,237 - INFO] Train Epoch : 34 Loss:	 0.011914	 lr:1e-05
2022-09-22 18:41:37,765 - INFO] Train Epoch : 35 Loss:	 0.014672	 lr:1e-05
2022-09-22 18:48:24,463 - INFO] Train Epoch : 36 Loss:	 0.012381	 lr:1e-05
2022-09-22 18:55:12,298 - INFO] Train Epoch : 37 Loss:	 0.009151	 lr:1e-05
2022-09-22 19:01:59,142 - INFO] Train Epoch : 38 Loss:	 0.011200	 lr:1e-05
2022-09-22 19:08:45,190 - INFO] Train Epoch : 39 Loss:	 0.011925	 lr:1e-05
2022-09-22 19:15:32,030 - INFO] Train Epoch : 40 Loss:	 0.010502	 lr:1e-05
2022-09-22 19:22:17,428 - INFO] Train Epoch : 41 Loss:	 0.010289	 lr:1e-05
2022-09-22 19:29:04,846 - INFO] Train Epoch : 42 Loss:	 0.013077	 lr:1e-05
2022-09-22 19:35:50,833 - INFO] Train Epoch : 43 Loss:	 0.014063	 lr:1e-05
2022-09-22 19:42:36,268 - INFO] Train Epoch : 44 Loss:	 0.012147	 lr:1e-05
2022-09-22 19:49:22,041 - INFO] Train Epoch : 45 Loss:	 0.013106	 lr:1e-05
2022-09-22 19:56:10,402 - INFO] Train Epoch : 46 Loss:	 0.012882	 lr:1e-05
2022-09-22 20:03:00,041 - INFO] Train Epoch : 47 Loss:	 0.008402	 lr:1e-05
2022-09-22 20:09:49,526 - INFO] Train Epoch : 48 Loss:	 0.012414	 lr:1e-05
2022-09-22 20:16:37,943 - INFO] Train Epoch : 49 Loss:	 0.011720	 lr:1e-05
2022-09-22 20:23:27,578 - INFO] Train Epoch : 50 Loss:	 0.010899	 lr:1e-05
2022-09-22 20:30:15,084 - INFO] Train Epoch : 51 Loss:	 0.013197	 lr:1e-05
2022-09-22 20:37:02,286 - INFO] Train Epoch : 52 Loss:	 0.010276	 lr:1e-05
2022-09-22 20:43:51,570 - INFO] Train Epoch : 53 Loss:	 0.011506	 lr:1e-05
2022-09-22 20:50:39,254 - INFO] Train Epoch : 54 Loss:	 0.012394	 lr:1e-05
2022-09-22 20:57:26,146 - INFO] Train Epoch : 55 Loss:	 0.010345	 lr:1e-05
2022-09-22 21:04:14,298 - INFO] Train Epoch : 56 Loss:	 0.012817	 lr:1e-05
2022-09-22 21:11:02,125 - INFO] Train Epoch : 57 Loss:	 0.010529	 lr:1e-05
2022-09-22 21:17:48,664 - INFO] Train Epoch : 58 Loss:	 0.011891	 lr:1e-05
2022-09-22 21:24:33,562 - INFO] Train Epoch : 59 Loss:	 0.012835	 lr:1e-05
2022-09-22 21:31:22,427 - INFO] Train Epoch : 60 Loss:	 0.010400	 lr:1e-05
2022-09-22 21:38:10,898 - INFO] Train Epoch : 61 Loss:	 0.010921	 lr:1e-05
2022-09-22 21:44:59,522 - INFO] Train Epoch : 62 Loss:	 0.010039	 lr:1e-05
2022-09-22 21:51:48,228 - INFO] Train Epoch : 63 Loss:	 0.010248	 lr:1e-05
2022-09-22 21:58:36,761 - INFO] Train Epoch : 64 Loss:	 0.009840	 lr:1e-05
2022-09-22 22:05:24,029 - INFO] Train Epoch : 65 Loss:	 0.009403	 lr:1e-05
2022-09-22 22:12:10,383 - INFO] Train Epoch : 66 Loss:	 0.012617	 lr:1e-05
2022-09-22 22:18:57,962 - INFO] Train Epoch : 67 Loss:	 0.012343	 lr:1e-05
2022-09-22 22:25:42,908 - INFO] Train Epoch : 68 Loss:	 0.012034	 lr:1e-05
2022-09-22 22:32:29,526 - INFO] Train Epoch : 69 Loss:	 0.014863	 lr:1e-05
2022-09-22 22:39:16,102 - INFO] Train Epoch : 70 Loss:	 0.009633	 lr:1e-05
2022-09-22 22:46:04,129 - INFO] Train Epoch : 71 Loss:	 0.010921	 lr:1e-05
2022-09-22 22:52:51,485 - INFO] Train Epoch : 72 Loss:	 0.013197	 lr:1.0000000000000002e-06
2022-09-22 22:59:37,983 - INFO] Train Epoch : 73 Loss:	 0.010117	 lr:1.0000000000000002e-06
2022-09-22 23:06:25,834 - INFO] Train Epoch : 74 Loss:	 0.013966	 lr:1.0000000000000002e-06
2022-09-22 23:13:11,917 - INFO] Train Epoch : 75 Loss:	 0.012017	 lr:1.0000000000000002e-06
2022-09-22 23:20:01,544 - INFO] Train Epoch : 76 Loss:	 0.010449	 lr:1.0000000000000002e-06
2022-09-22 23:26:49,290 - INFO] Train Epoch : 77 Loss:	 0.009514	 lr:1.0000000000000002e-06
2022-09-22 23:33:35,520 - INFO] Train Epoch : 78 Loss:	 0.009107	 lr:1.0000000000000002e-06
2022-09-22 23:40:20,442 - INFO] Train Epoch : 79 Loss:	 0.012739	 lr:1.0000000000000002e-06
2022-09-22 23:47:08,671 - INFO] Train Epoch : 80 Loss:	 0.008626	 lr:1.0000000000000002e-06
2022-09-22 23:53:55,292 - INFO] Train Epoch : 81 Loss:	 0.011340	 lr:1.0000000000000002e-06
2022-09-23 00:00:42,614 - INFO] Train Epoch : 82 Loss:	 0.011801	 lr:1.0000000000000002e-06
2022-09-23 00:07:29,347 - INFO] Train Epoch : 83 Loss:	 0.012337	 lr:1.0000000000000002e-06
2022-09-23 00:14:16,464 - INFO] Train Epoch : 84 Loss:	 0.012021	 lr:1.0000000000000002e-06
2022-09-23 00:21:04,778 - INFO] Train Epoch : 85 Loss:	 0.008689	 lr:1.0000000000000002e-06
2022-09-23 00:27:52,844 - INFO] Train Epoch : 86 Loss:	 0.010937	 lr:1.0000000000000002e-06
2022-09-23 00:34:42,106 - INFO] Train Epoch : 87 Loss:	 0.010430	 lr:1.0000000000000002e-06
2022-09-23 00:41:29,293 - INFO] Train Epoch : 88 Loss:	 0.010309	 lr:1.0000000000000002e-06
2022-09-23 00:48:15,747 - INFO] Train Epoch : 89 Loss:	 0.010983	 lr:1.0000000000000002e-06
2022-09-23 00:55:03,242 - INFO] Train Epoch : 90 Loss:	 0.009571	 lr:1.0000000000000002e-06
2022-09-23 01:01:51,228 - INFO] Train Epoch : 91 Loss:	 0.009944	 lr:1.0000000000000002e-06
2022-09-23 01:08:41,161 - INFO] Train Epoch : 92 Loss:	 0.008686	 lr:1.0000000000000002e-06
2022-09-23 01:15:27,618 - INFO] Train Epoch : 93 Loss:	 0.011599	 lr:1.0000000000000002e-06
2022-09-23 01:22:13,450 - INFO] Train Epoch : 94 Loss:	 0.011395	 lr:1.0000000000000002e-06
2022-09-23 01:28:59,253 - INFO] Train Epoch : 95 Loss:	 0.010843	 lr:1.0000000000000002e-06
2022-09-23 15:07:22,911 - INFO] DVC training
2022-09-23 15:07:22,912 - INFO] config : 
2022-09-23 15:07:22,913 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 15:07:46,735 - INFO] DVC training
2022-09-23 15:07:46,736 - INFO] config : 
2022-09-23 15:07:46,737 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 15:08:55,157 - INFO] global step 186277 : 

2022-09-23 15:08:55,158 - INFO] EWAP_eth dataset : average bpp : 0.065767, average psnr : 35.217393, average msssim: 0.980949

2022-09-23 15:14:17,580 - INFO] DVC training
2022-09-23 15:14:17,580 - INFO] config : 
2022-09-23 15:14:17,586 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 1024,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 15:21:07,879 - INFO] Train Epoch : 00 Loss:	 0.023373	 lr:1e-05
2022-09-23 15:27:50,762 - INFO] Train Epoch : 01 Loss:	 0.025067	 lr:1e-05
2022-09-23 15:29:20,368 - INFO] DVC training
2022-09-23 15:29:20,369 - INFO] config : 
2022-09-23 15:29:20,370 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 1024,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 15:30:28,517 - INFO] global step 2093 : 

2022-09-23 15:30:28,518 - INFO] EWAP_eth dataset : average bpp : 0.084907, average psnr : 35.348849, average msssim: 0.981910

2022-09-23 15:31:10,161 - INFO] DVC training
2022-09-23 15:31:10,161 - INFO] config : 
2022-09-23 15:31:10,163 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 15:38:01,565 - INFO] Train Epoch : 00 Loss:	 0.052338	 lr:1e-05
2022-09-23 15:44:47,508 - INFO] Train Epoch : 01 Loss:	 0.053583	 lr:1e-05
2022-09-23 15:51:30,351 - INFO] Train Epoch : 02 Loss:	 0.042438	 lr:1e-05
2022-09-23 15:58:14,443 - INFO] Train Epoch : 03 Loss:	 0.032906	 lr:1e-05
2022-09-23 16:01:03,967 - INFO] DVC training
2022-09-23 16:01:03,968 - INFO] config : 
2022-09-23 16:01:03,969 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 16:02:16,247 - INFO] DVC training
2022-09-23 16:02:16,247 - INFO] config : 
2022-09-23 16:02:16,254 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 16:03:36,734 - INFO] global step 2093 : 

2022-09-23 16:03:36,735 - INFO] EWAP_eth dataset : average bpp : 0.097675, average psnr : 35.532595, average msssim: 0.982482

2022-09-23 16:10:31,935 - INFO] DVC training
2022-09-23 16:10:31,935 - INFO] config : 
2022-09-23 16:10:31,937 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 16:11:40,604 - INFO] global step 2093 : 

2022-09-23 16:11:40,606 - INFO] EWAP_eth dataset : average bpp : 0.097670, average psnr : 35.532488, average msssim: 0.982482

2022-09-23 16:29:24,101 - INFO] DVC training
2022-09-23 16:29:24,101 - INFO] config : 
2022-09-23 16:29:24,103 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 16:35:24,293 - INFO] Train Epoch : 00 Loss:	 0.038025	 lr:1e-05
2022-09-23 16:36:20,810 - INFO] DVC training
2022-09-23 16:36:20,810 - INFO] config : 
2022-09-23 16:36:20,816 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-23 16:37:11,912 - INFO] global step 2093 : 

2022-09-23 16:37:11,912 - INFO] EWAP_eth dataset : average bpp : 0.100608, average psnr : 36.794856, average msssim: 0.991529

2022-09-23 16:41:21,829 - INFO] Train Epoch : 01 Loss:	 0.053885	 lr:1e-05
2022-09-23 16:47:14,038 - INFO] Train Epoch : 02 Loss:	 0.039741	 lr:1e-05
2022-09-23 16:53:19,250 - INFO] Train Epoch : 03 Loss:	 0.035639	 lr:1e-05
2022-09-23 17:00:07,823 - INFO] Train Epoch : 04 Loss:	 0.030303	 lr:1e-05
2022-09-23 17:06:47,609 - INFO] Train Epoch : 05 Loss:	 0.032682	 lr:1e-05
2022-09-23 17:13:31,721 - INFO] Train Epoch : 06 Loss:	 0.048151	 lr:1e-05
2022-09-23 17:19:55,457 - INFO] Train Epoch : 07 Loss:	 0.031933	 lr:1e-05
2022-09-23 17:26:25,713 - INFO] Train Epoch : 08 Loss:	 0.039072	 lr:1e-05
2022-09-23 17:32:57,853 - INFO] Train Epoch : 09 Loss:	 0.040843	 lr:1e-05
2022-09-23 17:39:32,015 - INFO] Train Epoch : 10 Loss:	 0.036440	 lr:1e-05
2022-09-23 17:46:07,440 - INFO] Train Epoch : 11 Loss:	 0.056693	 lr:1e-05
2022-09-23 17:52:30,847 - INFO] Train Epoch : 12 Loss:	 0.039761	 lr:1e-05
2022-09-23 17:59:06,293 - INFO] Train Epoch : 13 Loss:	 0.029822	 lr:1e-05
2022-09-23 18:05:14,230 - INFO] Train Epoch : 14 Loss:	 0.038777	 lr:1e-05
2022-09-23 18:11:09,224 - INFO] Train Epoch : 15 Loss:	 0.030729	 lr:1e-05
2022-09-23 18:17:03,090 - INFO] Train Epoch : 16 Loss:	 0.041117	 lr:1e-05
2022-09-23 18:22:53,979 - INFO] Train Epoch : 17 Loss:	 0.027507	 lr:1e-05
2022-09-23 18:28:43,029 - INFO] Train Epoch : 18 Loss:	 0.034790	 lr:1e-05
2022-09-23 18:34:32,096 - INFO] Train Epoch : 19 Loss:	 0.039835	 lr:1e-05
2022-09-23 18:40:19,319 - INFO] Train Epoch : 20 Loss:	 0.036256	 lr:1e-05
2022-09-23 18:46:08,111 - INFO] Train Epoch : 21 Loss:	 0.039565	 lr:1e-05
2022-09-23 18:51:53,532 - INFO] Train Epoch : 22 Loss:	 0.036489	 lr:1e-05
2022-09-23 18:57:41,173 - INFO] Train Epoch : 23 Loss:	 0.029118	 lr:1e-05
2022-09-23 19:03:34,871 - INFO] Train Epoch : 24 Loss:	 0.035506	 lr:1e-05
2022-09-23 19:09:24,996 - INFO] Train Epoch : 25 Loss:	 0.023464	 lr:1e-05
2022-09-23 19:15:16,612 - INFO] Train Epoch : 26 Loss:	 0.034192	 lr:1e-05
2022-09-23 19:21:06,218 - INFO] Train Epoch : 27 Loss:	 0.044134	 lr:1e-05
2022-09-23 19:26:57,641 - INFO] Train Epoch : 28 Loss:	 0.035110	 lr:1e-05
2022-09-23 19:32:50,246 - INFO] Train Epoch : 29 Loss:	 0.041380	 lr:1e-05
2022-09-23 19:38:41,948 - INFO] Train Epoch : 30 Loss:	 0.025278	 lr:1e-05
2022-09-23 19:44:33,409 - INFO] Train Epoch : 31 Loss:	 0.044699	 lr:1e-05
2022-09-23 19:50:24,666 - INFO] Train Epoch : 32 Loss:	 0.029174	 lr:1e-05
2022-09-23 19:56:15,048 - INFO] Train Epoch : 33 Loss:	 0.042262	 lr:1e-05
2022-09-23 20:02:07,616 - INFO] Train Epoch : 34 Loss:	 0.026664	 lr:1e-05
2022-09-23 20:07:56,969 - INFO] Train Epoch : 35 Loss:	 0.039195	 lr:1e-05
2022-09-23 20:13:48,369 - INFO] Train Epoch : 36 Loss:	 0.040326	 lr:1e-05
2022-09-23 20:19:38,477 - INFO] Train Epoch : 37 Loss:	 0.027149	 lr:1e-05
2022-09-23 20:25:29,442 - INFO] Train Epoch : 38 Loss:	 0.036989	 lr:1e-05
2022-09-23 20:31:23,530 - INFO] Train Epoch : 39 Loss:	 0.039471	 lr:1e-05
2022-09-23 20:37:16,054 - INFO] Train Epoch : 40 Loss:	 0.032610	 lr:1e-05
2022-09-23 20:43:06,562 - INFO] Train Epoch : 41 Loss:	 0.027843	 lr:1e-05
2022-09-23 20:48:56,549 - INFO] Train Epoch : 42 Loss:	 0.030591	 lr:1e-05
2022-09-23 20:54:48,443 - INFO] Train Epoch : 43 Loss:	 0.030879	 lr:1e-05
2022-09-23 21:00:40,440 - INFO] Train Epoch : 44 Loss:	 0.041638	 lr:1e-05
2022-09-23 21:06:31,670 - INFO] Train Epoch : 45 Loss:	 0.042694	 lr:1e-05
2022-09-23 21:12:24,646 - INFO] Train Epoch : 46 Loss:	 0.046734	 lr:1e-05
2022-09-23 21:18:16,549 - INFO] Train Epoch : 47 Loss:	 0.038440	 lr:1e-05
2022-09-23 21:24:07,172 - INFO] Train Epoch : 48 Loss:	 0.033592	 lr:1e-05
2022-09-23 21:29:59,230 - INFO] Train Epoch : 49 Loss:	 0.046898	 lr:1e-05
2022-09-23 21:35:51,031 - INFO] Train Epoch : 50 Loss:	 0.027588	 lr:1e-05
2022-09-23 21:41:41,043 - INFO] Train Epoch : 51 Loss:	 0.040999	 lr:1e-05
2022-09-23 21:47:31,307 - INFO] Train Epoch : 52 Loss:	 0.035144	 lr:1e-05
2022-09-23 21:53:22,698 - INFO] Train Epoch : 53 Loss:	 0.036084	 lr:1e-05
2022-09-23 21:59:14,162 - INFO] Train Epoch : 54 Loss:	 0.037554	 lr:1e-05
2022-09-23 22:05:05,083 - INFO] Train Epoch : 55 Loss:	 0.030870	 lr:1e-05
2022-09-23 22:10:57,754 - INFO] Train Epoch : 56 Loss:	 0.036947	 lr:1e-05
2022-09-23 22:16:51,056 - INFO] Train Epoch : 57 Loss:	 0.025906	 lr:1e-05
2022-09-23 22:22:41,218 - INFO] Train Epoch : 58 Loss:	 0.038880	 lr:1e-05
2022-09-23 22:28:30,739 - INFO] Train Epoch : 59 Loss:	 0.040823	 lr:1e-05
2022-09-23 22:34:27,068 - INFO] Train Epoch : 60 Loss:	 0.043928	 lr:1e-05
2022-09-23 22:40:17,440 - INFO] Train Epoch : 61 Loss:	 0.026822	 lr:1e-05
2022-09-23 22:46:07,719 - INFO] Train Epoch : 62 Loss:	 0.026878	 lr:1e-05
2022-09-23 22:51:59,258 - INFO] Train Epoch : 63 Loss:	 0.032728	 lr:1e-05
2022-09-23 22:57:48,774 - INFO] Train Epoch : 64 Loss:	 0.030940	 lr:1e-05
2022-09-23 23:03:40,048 - INFO] Train Epoch : 65 Loss:	 0.033264	 lr:1e-05
2022-09-23 23:09:32,838 - INFO] Train Epoch : 66 Loss:	 0.030192	 lr:1e-05
2022-09-23 23:15:21,628 - INFO] Train Epoch : 67 Loss:	 0.034119	 lr:1e-05
2022-09-23 23:21:11,835 - INFO] Train Epoch : 68 Loss:	 0.030687	 lr:1e-05
2022-09-23 23:27:03,737 - INFO] Train Epoch : 69 Loss:	 0.031714	 lr:1e-05
2022-09-23 23:32:54,777 - INFO] Train Epoch : 70 Loss:	 0.030472	 lr:1e-05
2022-09-23 23:38:46,688 - INFO] Train Epoch : 71 Loss:	 0.031037	 lr:1e-05
2022-09-23 23:44:39,562 - INFO] Train Epoch : 72 Loss:	 0.034732	 lr:1.0000000000000002e-06
2022-09-23 23:50:32,492 - INFO] Train Epoch : 73 Loss:	 0.026387	 lr:1.0000000000000002e-06
2022-09-23 23:56:25,549 - INFO] Train Epoch : 74 Loss:	 0.038346	 lr:1.0000000000000002e-06
2022-09-24 00:02:16,708 - INFO] Train Epoch : 75 Loss:	 0.035565	 lr:1.0000000000000002e-06
2022-09-24 00:08:07,008 - INFO] Train Epoch : 76 Loss:	 0.035555	 lr:1.0000000000000002e-06
2022-09-24 00:14:00,322 - INFO] Train Epoch : 77 Loss:	 0.032167	 lr:1.0000000000000002e-06
2022-09-24 00:19:52,695 - INFO] Train Epoch : 78 Loss:	 0.040172	 lr:1.0000000000000002e-06
2022-09-24 00:25:46,946 - INFO] Train Epoch : 79 Loss:	 0.048334	 lr:1.0000000000000002e-06
2022-09-24 00:31:36,432 - INFO] Train Epoch : 80 Loss:	 0.038252	 lr:1.0000000000000002e-06
2022-09-24 00:37:31,116 - INFO] Train Epoch : 81 Loss:	 0.039645	 lr:1.0000000000000002e-06
2022-09-24 00:43:24,606 - INFO] Train Epoch : 82 Loss:	 0.032921	 lr:1.0000000000000002e-06
2022-09-24 00:49:17,291 - INFO] Train Epoch : 83 Loss:	 0.039081	 lr:1.0000000000000002e-06
2022-09-24 00:55:08,702 - INFO] Train Epoch : 84 Loss:	 0.038527	 lr:1.0000000000000002e-06
2022-09-24 01:01:00,841 - INFO] Train Epoch : 85 Loss:	 0.032044	 lr:1.0000000000000002e-06
2022-09-24 01:06:52,965 - INFO] Train Epoch : 86 Loss:	 0.035360	 lr:1.0000000000000002e-06
2022-09-24 01:12:46,829 - INFO] Train Epoch : 87 Loss:	 0.032100	 lr:1.0000000000000002e-06
2022-09-24 01:18:38,579 - INFO] Train Epoch : 88 Loss:	 0.028360	 lr:1.0000000000000002e-06
2022-09-24 01:24:32,457 - INFO] Train Epoch : 89 Loss:	 0.036271	 lr:1.0000000000000002e-06
2022-09-24 01:30:24,172 - INFO] Train Epoch : 90 Loss:	 0.031858	 lr:1.0000000000000002e-06
2022-09-24 01:36:19,179 - INFO] Train Epoch : 91 Loss:	 0.036817	 lr:1.0000000000000002e-06
2022-09-24 01:42:11,419 - INFO] Train Epoch : 92 Loss:	 0.025592	 lr:1.0000000000000002e-06
2022-09-24 01:48:01,659 - INFO] Train Epoch : 93 Loss:	 0.038968	 lr:1.0000000000000002e-06
2022-09-24 01:53:51,307 - INFO] Train Epoch : 94 Loss:	 0.036620	 lr:1.0000000000000002e-06
2022-09-24 01:59:43,478 - INFO] Train Epoch : 95 Loss:	 0.035556	 lr:1.0000000000000002e-06
2022-09-24 15:46:06,970 - INFO] DVC training
2022-09-24 15:46:06,971 - INFO] config : 
2022-09-24 15:46:06,972 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-09-24 15:47:00,163 - INFO] global step 2093 : 

2022-09-24 15:47:00,163 - INFO] EWAP_eth dataset : average bpp : 0.078849, average psnr : 36.344372, average msssim: 0.989946

2022-10-11 14:42:48,294 - INFO] DVC training
2022-10-11 14:42:48,294 - INFO] config : 
2022-10-11 14:42:48,297 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 14:44:14,273 - INFO] global step 0 : 

2022-10-11 14:44:14,274 - INFO] EWAP_eth dataset : average bpp : 0.082214, average psnr : 35.637715, average msssim: 0.989290

2022-10-11 14:54:57,780 - INFO] DVC training
2022-10-11 14:54:57,780 - INFO] config : 
2022-10-11 14:54:57,781 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 14:56:00,626 - INFO] global step 0 : 

2022-10-11 14:56:00,627 - INFO] EWAP_eth dataset : average bpp : 0.083639, average psnr : 35.271714, average msssim: 0.988860

2022-10-11 14:57:29,839 - INFO] DVC training
2022-10-11 14:57:29,839 - INFO] config : 
2022-10-11 14:57:29,840 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 14:58:32,447 - INFO] global step 0 : 

2022-10-11 14:58:32,448 - INFO] EWAP_eth dataset : average bpp : 0.079735, average psnr : 35.749070, average msssim: 0.989920

2022-10-11 14:59:17,304 - INFO] DVC training
2022-10-11 14:59:17,304 - INFO] config : 
2022-10-11 14:59:17,306 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:00:17,948 - INFO] global step 0 : 

2022-10-11 15:00:17,949 - INFO] EWAP_eth dataset : average bpp : 0.080792, average psnr : 35.668098, average msssim: 0.989646

2022-10-11 15:01:37,937 - INFO] DVC training
2022-10-11 15:01:37,937 - INFO] config : 
2022-10-11 15:01:37,943 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:02:36,076 - INFO] global step 0 : 

2022-10-11 15:02:36,076 - INFO] EWAP_eth dataset : average bpp : 0.080933, average psnr : 35.580402, average msssim: 0.990567

2022-10-11 15:06:32,438 - INFO] DVC training
2022-10-11 15:06:32,438 - INFO] config : 
2022-10-11 15:06:32,439 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:08:01,141 - INFO] global step 0 : 

2022-10-11 15:08:01,142 - INFO] EWAP_eth dataset : average bpp : 0.070573, average psnr : 34.458769, average msssim: 0.986387

2022-10-11 15:09:29,015 - INFO] DVC training
2022-10-11 15:09:29,016 - INFO] config : 
2022-10-11 15:09:29,022 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:11:11,263 - INFO] global step 0 : 

2022-10-11 15:11:11,264 - INFO] EWAP_eth dataset : average bpp : 0.062096, average psnr : 33.425658, average msssim: 0.982911

2022-10-11 15:13:14,481 - INFO] DVC training
2022-10-11 15:13:14,481 - INFO] config : 
2022-10-11 15:13:14,482 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:14:14,025 - INFO] global step 0 : 

2022-10-11 15:14:14,026 - INFO] EWAP_eth dataset : average bpp : 0.125833, average psnr : 36.327218, average msssim: 0.990947

2022-10-11 15:16:52,365 - INFO] DVC training
2022-10-11 15:16:52,365 - INFO] config : 
2022-10-11 15:16:52,366 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:17:50,538 - INFO] global step 0 : 

2022-10-11 15:17:50,538 - INFO] EWAP_eth dataset : average bpp : 0.123322, average psnr : 35.539166, average msssim: 0.989069

2022-10-11 15:19:04,244 - INFO] DVC training
2022-10-11 15:19:04,244 - INFO] config : 
2022-10-11 15:19:04,250 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:20:04,834 - INFO] global step 0 : 

2022-10-11 15:20:04,835 - INFO] EWAP_eth dataset : average bpp : 0.134094, average psnr : 36.463570, average msssim: 0.991213

2022-10-11 15:22:19,296 - INFO] DVC training
2022-10-11 15:22:19,297 - INFO] config : 
2022-10-11 15:22:19,304 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:23:38,535 - INFO] global step 0 : 

2022-10-11 15:23:38,536 - INFO] EWAP_eth dataset : average bpp : 0.116032, average psnr : 36.754394, average msssim: 0.991936

2022-10-11 15:25:15,574 - INFO] DVC training
2022-10-11 15:25:15,575 - INFO] config : 
2022-10-11 15:25:15,576 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:26:16,054 - INFO] global step 0 : 

2022-10-11 15:26:16,055 - INFO] EWAP_eth dataset : average bpp : 0.117853, average psnr : 36.743023, average msssim: 0.991806

2022-10-11 15:27:27,653 - INFO] DVC training
2022-10-11 15:27:27,653 - INFO] config : 
2022-10-11 15:27:27,655 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:28:25,765 - INFO] global step 0 : 

2022-10-11 15:28:25,765 - INFO] EWAP_eth dataset : average bpp : 0.134092, average psnr : 36.463519, average msssim: 0.991213

2022-10-11 15:29:26,149 - INFO] DVC training
2022-10-11 15:29:26,149 - INFO] config : 
2022-10-11 15:29:26,151 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:30:27,850 - INFO] global step 0 : 

2022-10-11 15:30:27,851 - INFO] EWAP_eth dataset : average bpp : 0.116875, average psnr : 36.594159, average msssim: 0.992202

2022-10-11 15:31:35,812 - INFO] DVC training
2022-10-11 15:31:35,812 - INFO] config : 
2022-10-11 15:31:35,813 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:32:36,457 - INFO] global step 0 : 

2022-10-11 15:32:36,458 - INFO] EWAP_eth dataset : average bpp : 0.117992, average psnr : 36.834183, average msssim: 0.991652

2022-10-11 15:34:11,979 - INFO] DVC training
2022-10-11 15:34:11,980 - INFO] config : 
2022-10-11 15:34:11,981 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:35:15,449 - INFO] global step 0 : 

2022-10-11 15:35:15,450 - INFO] EWAP_eth dataset : average bpp : 0.122320, average psnr : 36.620696, average msssim: 0.991979

2022-10-11 15:36:44,147 - INFO] DVC training
2022-10-11 15:36:44,147 - INFO] config : 
2022-10-11 15:36:44,153 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:37:44,374 - INFO] global step 0 : 

2022-10-11 15:37:44,375 - INFO] EWAP_eth dataset : average bpp : 0.120645, average psnr : 36.718930, average msssim: 0.991639

2022-10-11 15:54:23,920 - INFO] DVC training
2022-10-11 15:54:23,920 - INFO] config : 
2022-10-11 15:54:23,921 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:56:35,726 - INFO] global step 0 : 

2022-10-11 15:56:35,727 - INFO] EWAP_eth dataset : average bpp : 0.134209, average psnr : 35.732161, average msssim: 0.985999

2022-10-11 15:58:00,411 - INFO] DVC training
2022-10-11 15:58:00,411 - INFO] config : 
2022-10-11 15:58:00,418 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 15:59:18,285 - INFO] global step 0 : 

2022-10-11 15:59:18,285 - INFO] EWAP_eth dataset : average bpp : 0.117862, average psnr : 36.742967, average msssim: 0.991806

2022-10-11 16:02:49,495 - INFO] DVC training
2022-10-11 16:02:49,496 - INFO] config : 
2022-10-11 16:02:49,496 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 16:03:10,806 - INFO] DVC training
2022-10-11 16:03:10,807 - INFO] config : 
2022-10-11 16:03:10,808 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 16:05:21,586 - INFO] global step 0 : 

2022-10-11 16:05:21,587 - INFO] EWAP_eth dataset : average bpp : 0.299991, average psnr : 32.360539, average msssim: 0.984525

2022-10-11 16:07:00,690 - INFO] global step 0 : 

2022-10-11 16:07:00,723 - INFO] EWAP_eth dataset : average bpp : 0.148365, average psnr : 34.990892, average msssim: 0.987089

2022-10-11 16:07:53,321 - INFO] DVC training
2022-10-11 16:07:53,322 - INFO] config : 
2022-10-11 16:07:53,323 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 16:08:51,942 - INFO] global step 0 : 

2022-10-11 16:08:51,943 - INFO] EWAP_eth dataset : average bpp : 0.131438, average psnr : 35.668547, average msssim: 0.986264

2022-10-11 16:13:26,269 - INFO] global step 0 : 

2022-10-11 16:13:26,270 - INFO] EWAP_eth dataset : average bpp : 0.307269, average psnr : 32.711812, average msssim: 0.985384

2022-10-11 16:13:31,461 - INFO] global step 0 : 

2022-10-11 16:13:31,462 - INFO] EWAP_eth dataset : average bpp : 0.126640, average psnr : 35.430628, average msssim: 0.986478

2022-10-11 16:16:08,134 - INFO] global step 0 : 

2022-10-11 16:16:08,135 - INFO] EWAP_eth dataset : average bpp : 0.180514, average psnr : 33.649701, average msssim: 0.988253

2022-10-11 16:17:02,054 - INFO] global step 0 : 

2022-10-11 16:17:02,056 - INFO] EWAP_eth dataset : average bpp : 0.157880, average psnr : 35.171120, average msssim: 0.987516

2022-10-11 16:18:06,128 - INFO] global step 0 : 

2022-10-11 16:18:06,129 - INFO] EWAP_eth dataset : average bpp : 0.148163, average psnr : 35.411295, average msssim: 0.986652

2022-10-11 16:20:08,747 - INFO] global step 0 : 

2022-10-11 16:20:08,749 - INFO] EWAP_eth dataset : average bpp : 0.139912, average psnr : 35.850303, average msssim: 0.986748

2022-10-11 16:20:23,835 - INFO] global step 0 : 

2022-10-11 16:20:23,836 - INFO] EWAP_eth dataset : average bpp : 0.140030, average psnr : 35.737366, average msssim: 0.986256

2022-10-11 16:22:41,454 - INFO] global step 0 : 

2022-10-11 16:22:41,455 - INFO] EWAP_eth dataset : average bpp : 0.189840, average psnr : 33.738929, average msssim: 0.988020

2022-10-11 16:23:24,065 - INFO] global step 0 : 

2022-10-11 16:23:24,123 - INFO] EWAP_eth dataset : average bpp : 0.136687, average psnr : 35.572965, average msssim: 0.986908

2022-10-11 16:26:03,032 - INFO] global step 0 : 

2022-10-11 16:26:03,036 - INFO] EWAP_eth dataset : average bpp : 0.152760, average psnr : 35.373193, average msssim: 0.986381

2022-10-11 16:27:17,842 - INFO] global step 0 : 

2022-10-11 16:27:17,846 - INFO] EWAP_eth dataset : average bpp : 0.190979, average psnr : 33.837320, average msssim: 0.988665

2022-10-11 16:29:19,335 - INFO] global step 0 : 

2022-10-11 16:29:19,339 - INFO] EWAP_eth dataset : average bpp : 0.134212, average psnr : 35.732075, average msssim: 0.985999

2022-10-11 16:30:21,625 - INFO] global step 0 : 

2022-10-11 16:30:21,630 - INFO] EWAP_eth dataset : average bpp : 0.156775, average psnr : 35.599091, average msssim: 0.987142

2022-10-11 16:32:51,850 - INFO] global step 0 : 

2022-10-11 16:32:51,852 - INFO] EWAP_eth dataset : average bpp : 0.147521, average psnr : 35.937606, average msssim: 0.986731

2022-10-11 16:50:38,512 - INFO] DVC training
2022-10-11 16:50:38,512 - INFO] config : 
2022-10-11 16:50:38,513 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 16:51:27,667 - INFO] global step 0 : 

2022-10-11 16:51:27,667 - INFO] EWAP_eth dataset : average bpp : 0.297977, average psnr : 30.078864, average msssim: 0.991097

2022-10-11 16:52:03,204 - INFO] global step 0 : 

2022-10-11 16:52:03,204 - INFO] EWAP_eth dataset : average bpp : 0.307148, average psnr : 29.871087, average msssim: 0.991157

2022-10-11 16:52:39,274 - INFO] global step 0 : 

2022-10-11 16:52:39,274 - INFO] EWAP_eth dataset : average bpp : 0.303119, average psnr : 30.007586, average msssim: 0.991376

2022-10-11 16:55:08,096 - INFO] DVC training
2022-10-11 16:55:08,096 - INFO] config : 
2022-10-11 16:55:08,102 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 16:55:56,947 - INFO] global step 0 : 

2022-10-11 16:55:56,948 - INFO] EWAP_eth dataset : average bpp : 0.297975, average psnr : 30.078750, average msssim: 0.991097

2022-10-11 16:56:33,226 - INFO] global step 0 : 

2022-10-11 16:56:33,228 - INFO] EWAP_eth dataset : average bpp : 0.307155, average psnr : 29.871026, average msssim: 0.991157

2022-10-11 16:57:09,771 - INFO] global step 0 : 

2022-10-11 16:57:09,771 - INFO] EWAP_eth dataset : average bpp : 0.303120, average psnr : 30.007559, average msssim: 0.991376

2022-10-11 16:57:41,290 - INFO] DVC training
2022-10-11 16:57:41,290 - INFO] config : 
2022-10-11 16:57:41,291 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 16:58:30,456 - INFO] global step 0 : 

2022-10-11 16:58:30,456 - INFO] EWAP_eth dataset : average bpp : 0.297945, average psnr : 30.078930, average msssim: 0.991098

2022-10-11 16:59:06,695 - INFO] global step 0 : 

2022-10-11 16:59:06,696 - INFO] EWAP_eth dataset : average bpp : 0.307189, average psnr : 29.871216, average msssim: 0.991158

2022-10-11 16:59:44,682 - INFO] global step 0 : 

2022-10-11 16:59:44,682 - INFO] EWAP_eth dataset : average bpp : 0.303114, average psnr : 30.007629, average msssim: 0.991376

2022-10-11 17:02:20,626 - INFO] global step 0 : 

2022-10-11 17:02:20,628 - INFO] EWAP_eth dataset : average bpp : 0.300603, average psnr : 30.201113, average msssim: 0.991100

2022-10-11 17:04:18,423 - INFO] global step 0 : 

2022-10-11 17:04:18,425 - INFO] EWAP_eth dataset : average bpp : 0.344166, average psnr : 29.391765, average msssim: 0.991216

2022-10-11 17:04:54,338 - INFO] global step 0 : 

2022-10-11 17:04:54,338 - INFO] EWAP_eth dataset : average bpp : 0.297827, average psnr : 30.093351, average msssim: 0.991360

2022-10-11 17:05:30,474 - INFO] global step 0 : 

2022-10-11 17:05:30,475 - INFO] EWAP_eth dataset : average bpp : 0.300575, average psnr : 30.037360, average msssim: 0.991655

2022-10-11 17:06:07,403 - INFO] global step 0 : 

2022-10-11 17:06:07,403 - INFO] EWAP_eth dataset : average bpp : 0.335045, average psnr : 29.380003, average msssim: 0.991059

2022-10-11 17:06:44,080 - INFO] global step 0 : 

2022-10-11 17:06:44,081 - INFO] EWAP_eth dataset : average bpp : 0.322121, average psnr : 29.579678, average msssim: 0.991465

2022-10-11 17:07:21,103 - INFO] global step 0 : 

2022-10-11 17:07:21,103 - INFO] EWAP_eth dataset : average bpp : 0.332370, average psnr : 29.524644, average msssim: 0.991450

2022-10-11 17:07:57,411 - INFO] global step 0 : 

2022-10-11 17:07:57,418 - INFO] EWAP_eth dataset : average bpp : 0.309710, average psnr : 29.866208, average msssim: 0.990917

2022-10-11 17:08:33,591 - INFO] global step 0 : 

2022-10-11 17:08:33,591 - INFO] EWAP_eth dataset : average bpp : 0.341898, average psnr : 29.044889, average msssim: 0.990889

2022-10-11 17:09:09,874 - INFO] global step 0 : 

2022-10-11 17:09:09,875 - INFO] EWAP_eth dataset : average bpp : 0.302717, average psnr : 29.754746, average msssim: 0.991100

2022-10-11 17:09:49,453 - INFO] global step 0 : 

2022-10-11 17:09:49,453 - INFO] EWAP_eth dataset : average bpp : 0.335647, average psnr : 29.191529, average msssim: 0.990680

2022-10-11 17:10:32,971 - INFO] global step 0 : 

2022-10-11 17:10:32,972 - INFO] EWAP_eth dataset : average bpp : 0.386875, average psnr : 28.352621, average msssim: 0.990601

2022-10-11 17:11:16,862 - INFO] global step 0 : 

2022-10-11 17:11:16,863 - INFO] EWAP_eth dataset : average bpp : 0.351321, average psnr : 28.829182, average msssim: 0.990620

2022-10-11 17:11:54,635 - INFO] global step 0 : 

2022-10-11 17:11:54,636 - INFO] EWAP_eth dataset : average bpp : 0.369224, average psnr : 28.561626, average msssim: 0.990875

2022-10-11 17:12:30,503 - INFO] global step 0 : 

2022-10-11 17:12:30,503 - INFO] EWAP_eth dataset : average bpp : 0.336249, average psnr : 29.085892, average msssim: 0.991211

2022-10-11 17:13:06,836 - INFO] global step 0 : 

2022-10-11 17:13:06,837 - INFO] EWAP_eth dataset : average bpp : 0.359152, average psnr : 28.476671, average msssim: 0.990564

2022-10-11 17:13:42,857 - INFO] global step 0 : 

2022-10-11 17:13:42,858 - INFO] EWAP_eth dataset : average bpp : 0.351953, average psnr : 28.908939, average msssim: 0.990636

2022-10-11 17:14:19,059 - INFO] global step 0 : 

2022-10-11 17:14:19,060 - INFO] EWAP_eth dataset : average bpp : 0.348343, average psnr : 28.906698, average msssim: 0.990400

2022-10-11 17:15:08,951 - INFO] DVC training
2022-10-11 17:15:08,951 - INFO] config : 
2022-10-11 17:15:08,957 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:15:58,345 - INFO] global step 0 : 

2022-10-11 17:15:58,346 - INFO] EWAP_eth dataset : average bpp : 0.319705, average psnr : 30.264665, average msssim: 0.991487

2022-10-11 17:16:35,047 - INFO] global step 0 : 

2022-10-11 17:16:35,047 - INFO] EWAP_eth dataset : average bpp : 0.326647, average psnr : 30.114213, average msssim: 0.991652

2022-10-11 17:17:11,284 - INFO] global step 0 : 

2022-10-11 17:17:11,285 - INFO] EWAP_eth dataset : average bpp : 0.324866, average psnr : 30.202699, average msssim: 0.991762

2022-10-11 17:17:46,998 - INFO] global step 0 : 

2022-10-11 17:17:46,999 - INFO] EWAP_eth dataset : average bpp : 0.324200, average psnr : 30.367833, average msssim: 0.991445

2022-10-11 17:18:21,874 - INFO] global step 0 : 

2022-10-11 17:18:21,875 - INFO] EWAP_eth dataset : average bpp : 0.367732, average psnr : 29.537116, average msssim: 0.991450

2022-10-11 17:18:59,072 - INFO] global step 0 : 

2022-10-11 17:18:59,073 - INFO] EWAP_eth dataset : average bpp : 0.319499, average psnr : 30.266642, average msssim: 0.991709

2022-10-11 17:19:34,435 - INFO] global step 0 : 

2022-10-11 17:19:34,436 - INFO] EWAP_eth dataset : average bpp : 0.325981, average psnr : 30.115800, average msssim: 0.991790

2022-10-11 17:20:11,002 - INFO] global step 0 : 

2022-10-11 17:20:11,002 - INFO] EWAP_eth dataset : average bpp : 0.354330, average psnr : 29.645581, average msssim: 0.991663

2022-10-11 17:20:47,482 - INFO] global step 0 : 

2022-10-11 17:20:47,483 - INFO] EWAP_eth dataset : average bpp : 0.346079, average psnr : 29.728484, average msssim: 0.991739

2022-10-11 17:21:24,036 - INFO] global step 0 : 

2022-10-11 17:21:24,037 - INFO] EWAP_eth dataset : average bpp : 0.356239, average psnr : 29.666052, average msssim: 0.991726

2022-10-11 17:22:02,375 - INFO] DVC training
2022-10-11 17:22:02,375 - INFO] config : 
2022-10-11 17:22:02,376 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:23:37,811 - INFO] DVC training
2022-10-11 17:23:37,811 - INFO] config : 
2022-10-11 17:23:37,812 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:25:28,747 - INFO] DVC training
2022-10-11 17:25:28,747 - INFO] config : 
2022-10-11 17:25:28,748 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:26:04,914 - INFO] DVC training
2022-10-11 17:26:04,914 - INFO] config : 
2022-10-11 17:26:04,915 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:26:44,806 - INFO] DVC training
2022-10-11 17:26:44,806 - INFO] config : 
2022-10-11 17:26:44,812 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:27:34,657 - INFO] global step 0 : 

2022-10-11 17:27:34,658 - INFO] EWAP_eth dataset : average bpp : 0.353744, average psnr : 29.194521, average msssim: 0.990891

2022-10-11 17:28:11,442 - INFO] global step 0 : 

2022-10-11 17:28:11,442 - INFO] EWAP_eth dataset : average bpp : 0.400111, average psnr : 28.838169, average msssim: 0.990850

2022-10-11 17:28:47,703 - INFO] global step 0 : 

2022-10-11 17:28:47,703 - INFO] EWAP_eth dataset : average bpp : 0.355912, average psnr : 29.347973, average msssim: 0.990984

2022-10-11 17:29:24,178 - INFO] global step 0 : 

2022-10-11 17:29:24,179 - INFO] EWAP_eth dataset : average bpp : 0.358116, average psnr : 29.121872, average msssim: 0.991309

2022-10-11 17:30:00,356 - INFO] global step 0 : 

2022-10-11 17:30:00,357 - INFO] EWAP_eth dataset : average bpp : 0.370273, average psnr : 29.140268, average msssim: 0.990929

2022-10-11 17:30:28,388 - INFO] DVC training
2022-10-11 17:30:28,388 - INFO] config : 
2022-10-11 17:30:28,390 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:31:17,035 - INFO] global step 0 : 

2022-10-11 17:31:17,036 - INFO] EWAP_eth dataset : average bpp : 0.353739, average psnr : 29.194456, average msssim: 0.990890

2022-10-11 17:32:30,952 - INFO] global step 0 : 

2022-10-11 17:32:30,953 - INFO] EWAP_eth dataset : average bpp : 0.400145, average psnr : 28.838081, average msssim: 0.990850

2022-10-11 17:35:33,710 - INFO] DVC training
2022-10-11 17:35:33,710 - INFO] config : 
2022-10-11 17:35:33,711 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:36:13,175 - INFO] global step 0 : 

2022-10-11 17:36:13,175 - INFO] EWAP_eth dataset : average bpp : 0.353723, average psnr : 29.194939, average msssim: 0.990890

2022-10-11 17:36:42,434 - INFO] global step 0 : 

2022-10-11 17:36:42,434 - INFO] EWAP_eth dataset : average bpp : 0.400067, average psnr : 28.838241, average msssim: 0.990850

2022-10-11 17:37:11,441 - INFO] global step 0 : 

2022-10-11 17:37:11,441 - INFO] EWAP_eth dataset : average bpp : 0.355910, average psnr : 29.347955, average msssim: 0.990983

2022-10-11 17:37:38,102 - INFO] global step 0 : 

2022-10-11 17:37:38,103 - INFO] EWAP_eth dataset : average bpp : 0.358123, average psnr : 29.121864, average msssim: 0.991309

2022-10-11 17:38:06,843 - INFO] global step 0 : 

2022-10-11 17:38:06,844 - INFO] EWAP_eth dataset : average bpp : 0.370271, average psnr : 29.140264, average msssim: 0.990929

2022-10-11 17:38:41,265 - INFO] global step 0 : 

2022-10-11 17:38:41,266 - INFO] EWAP_eth dataset : average bpp : 0.373681, average psnr : 29.126145, average msssim: 0.991129

2022-10-11 17:39:16,360 - INFO] global step 0 : 

2022-10-11 17:39:16,361 - INFO] EWAP_eth dataset : average bpp : 0.380893, average psnr : 28.710656, average msssim: 0.991087

2022-10-11 17:40:48,500 - INFO] DVC training
2022-10-11 17:40:48,500 - INFO] config : 
2022-10-11 17:40:48,501 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:41:45,149 - INFO] DVC training
2022-10-11 17:41:45,150 - INFO] config : 
2022-10-11 17:41:45,157 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:42:26,174 - INFO] global step 0 : 

2022-10-11 17:42:26,175 - INFO] EWAP_eth dataset : average bpp : 0.353721, average psnr : 29.194946, average msssim: 0.990890

2022-10-11 17:43:02,384 - INFO] DVC training
2022-10-11 17:43:02,384 - INFO] config : 
2022-10-11 17:43:02,385 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:43:53,262 - INFO] DVC training
2022-10-11 17:43:53,262 - INFO] config : 
2022-10-11 17:43:53,269 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:45:47,857 - INFO] DVC training
2022-10-11 17:45:47,858 - INFO] config : 
2022-10-11 17:45:47,859 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:46:50,278 - INFO] DVC training
2022-10-11 17:46:50,278 - INFO] config : 
2022-10-11 17:46:50,279 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:48:56,571 - INFO] DVC training
2022-10-11 17:48:56,571 - INFO] config : 
2022-10-11 17:48:56,573 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:49:30,231 - INFO] DVC training
2022-10-11 17:49:30,232 - INFO] config : 
2022-10-11 17:49:30,233 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:50:11,897 - INFO] global step 0 : 

2022-10-11 17:50:11,897 - INFO] EWAP_eth dataset : average bpp : 0.323421, average psnr : 32.099993, average msssim: 0.995248

2022-10-11 17:50:43,440 - INFO] global step 0 : 

2022-10-11 17:50:43,440 - INFO] EWAP_eth dataset : average bpp : 0.369940, average psnr : 31.455304, average msssim: 0.994784

2022-10-11 17:51:03,125 - INFO] DVC training
2022-10-11 17:51:03,125 - INFO] config : 
2022-10-11 17:51:03,126 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:51:40,470 - INFO] global step 0 : 

2022-10-11 17:51:40,470 - INFO] EWAP_eth dataset : average bpp : 0.353740, average psnr : 29.194445, average msssim: 0.990890

2022-10-11 17:52:08,935 - INFO] global step 0 : 

2022-10-11 17:52:08,935 - INFO] EWAP_eth dataset : average bpp : 0.400100, average psnr : 28.837948, average msssim: 0.990850

2022-10-11 17:52:36,404 - INFO] global step 0 : 

2022-10-11 17:52:36,405 - INFO] EWAP_eth dataset : average bpp : 0.355915, average psnr : 29.347976, average msssim: 0.990984

2022-10-11 17:53:06,802 - INFO] DVC training
2022-10-11 17:53:06,803 - INFO] config : 
2022-10-11 17:53:06,809 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:55:41,477 - INFO] DVC training
2022-10-11 17:55:41,477 - INFO] config : 
2022-10-11 17:55:41,483 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:56:26,163 - INFO] DVC training
2022-10-11 17:56:26,163 - INFO] config : 
2022-10-11 17:56:26,169 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:56:53,887 - INFO] DVC training
2022-10-11 17:56:53,887 - INFO] config : 
2022-10-11 17:56:53,888 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:57:32,635 - INFO] global step 0 : 

2022-10-11 17:57:32,636 - INFO] EWAP_eth dataset : average bpp : 0.326701, average psnr : 29.446975, average msssim: 0.991445

2022-10-11 17:58:03,649 - INFO] global step 0 : 

2022-10-11 17:58:03,650 - INFO] EWAP_eth dataset : average bpp : 0.363192, average psnr : 29.170380, average msssim: 0.991645

2022-10-11 17:58:35,535 - INFO] global step 0 : 

2022-10-11 17:58:35,536 - INFO] EWAP_eth dataset : average bpp : 0.328610, average psnr : 29.564594, average msssim: 0.991580

2022-10-11 17:58:53,138 - INFO] DVC training
2022-10-11 17:58:53,138 - INFO] config : 
2022-10-11 17:58:53,139 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 17:59:32,575 - INFO] global step 0 : 

2022-10-11 17:59:32,576 - INFO] EWAP_eth dataset : average bpp : 0.292614, average psnr : 30.501509, average msssim: 0.992046

2022-10-11 18:00:04,037 - INFO] global step 0 : 

2022-10-11 18:00:04,038 - INFO] EWAP_eth dataset : average bpp : 0.300054, average psnr : 30.326632, average msssim: 0.992050

2022-10-11 18:00:37,281 - INFO] global step 0 : 

2022-10-11 18:00:37,282 - INFO] EWAP_eth dataset : average bpp : 0.297212, average psnr : 30.453252, average msssim: 0.992217

2022-10-11 18:00:51,423 - INFO] DVC training
2022-10-11 18:00:51,423 - INFO] config : 
2022-10-11 18:00:51,430 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 18:01:12,727 - INFO] global step 0 : 

2022-10-11 18:01:12,728 - INFO] EWAP_eth dataset : average bpp : 0.296993, average psnr : 30.542976, average msssim: 0.991815

2022-10-11 18:02:41,945 - INFO] global step 0 : 

2022-10-11 18:02:41,946 - INFO] EWAP_eth dataset : average bpp : 0.335056, average psnr : 29.814323, average msssim: 0.992028

2022-10-11 18:04:18,133 - INFO] global step 0 : 

2022-10-11 18:04:18,135 - INFO] EWAP_eth dataset : average bpp : 0.291447, average psnr : 30.489374, average msssim: 0.992215

2022-10-11 18:05:06,240 - INFO] global step 0 : 

2022-10-11 18:05:06,241 - INFO] EWAP_eth dataset : average bpp : 0.126645, average psnr : 35.430689, average msssim: 0.986478

2022-10-11 18:05:16,450 - INFO] global step 0 : 

2022-10-11 18:05:16,451 - INFO] EWAP_eth dataset : average bpp : 0.293848, average psnr : 30.378169, average msssim: 0.992315

2022-10-11 18:06:16,659 - INFO] global step 0 : 

2022-10-11 18:06:16,660 - INFO] EWAP_eth dataset : average bpp : 0.326506, average psnr : 29.775302, average msssim: 0.991933

2022-10-11 18:07:28,945 - INFO] global step 0 : 

2022-10-11 18:07:28,946 - INFO] EWAP_eth dataset : average bpp : 0.315388, average psnr : 29.974616, average msssim: 0.992247

2022-10-11 18:08:27,836 - INFO] global step 0 : 

2022-10-11 18:08:27,837 - INFO] EWAP_eth dataset : average bpp : 0.322164, average psnr : 29.956595, average msssim: 0.992257

2022-10-11 18:08:35,643 - INFO] global step 0 : 

2022-10-11 18:08:35,644 - INFO] EWAP_eth dataset : average bpp : 0.126653, average psnr : 35.430595, average msssim: 0.986478

2022-10-11 18:09:03,556 - INFO] global step 0 : 

2022-10-11 18:09:03,556 - INFO] EWAP_eth dataset : average bpp : 0.306295, average psnr : 30.246347, average msssim: 0.991781

2022-10-11 18:09:14,233 - INFO] DVC training
2022-10-11 18:09:14,233 - INFO] config : 
2022-10-11 18:09:14,240 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 18:09:38,048 - INFO] global step 0 : 

2022-10-11 18:09:38,048 - INFO] EWAP_eth dataset : average bpp : 0.331263, average psnr : 29.530947, average msssim: 0.991994

2022-10-11 18:10:09,129 - INFO] global step 0 : 

2022-10-11 18:10:09,130 - INFO] EWAP_eth dataset : average bpp : 0.306131, average psnr : 30.031931, average msssim: 0.991578

2022-10-11 18:10:27,375 - INFO] DVC training
2022-10-11 18:10:27,375 - INFO] config : 
2022-10-11 18:10:27,424 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 18:10:39,940 - INFO] global step 0 : 

2022-10-11 18:10:39,940 - INFO] EWAP_eth dataset : average bpp : 0.326676, average psnr : 29.655601, average msssim: 0.991677

2022-10-11 18:11:42,927 - INFO] global step 0 : 

2022-10-11 18:11:42,928 - INFO] EWAP_eth dataset : average bpp : 0.366891, average psnr : 28.901361, average msssim: 0.991803

2022-10-11 18:12:20,440 - INFO] global step 0 : 

2022-10-11 18:12:20,440 - INFO] EWAP_eth dataset : average bpp : 0.342918, average psnr : 29.284529, average msssim: 0.991800

2022-10-11 18:12:37,525 - INFO] DVC training
2022-10-11 18:12:37,525 - INFO] config : 
2022-10-11 18:12:37,530 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 18:12:47,533 - INFO] global step 0 : 

2022-10-11 18:12:47,534 - INFO] EWAP_eth dataset : average bpp : 0.355653, average psnr : 28.996399, average msssim: 0.991905

2022-10-11 18:13:37,474 - INFO] global step 0 : 

2022-10-11 18:13:37,475 - INFO] EWAP_eth dataset : average bpp : 0.331815, average psnr : 29.423790, average msssim: 0.991972

2022-10-11 18:15:03,923 - INFO] global step 0 : 

2022-10-11 18:15:03,924 - INFO] EWAP_eth dataset : average bpp : 0.352610, average psnr : 28.878658, average msssim: 0.991471

2022-10-11 18:15:34,663 - INFO] global step 0 : 

2022-10-11 18:15:34,663 - INFO] EWAP_eth dataset : average bpp : 0.117249, average psnr : 36.601920, average msssim: 0.991684

2022-10-11 18:16:47,748 - INFO] global step 0 : 

2022-10-11 18:16:47,749 - INFO] EWAP_eth dataset : average bpp : 0.116025, average psnr : 36.754374, average msssim: 0.991936

2022-10-11 18:18:01,248 - INFO] global step 0 : 

2022-10-11 18:18:01,248 - INFO] EWAP_eth dataset : average bpp : 0.117858, average psnr : 36.742996, average msssim: 0.991807

2022-10-11 18:19:15,132 - INFO] global step 0 : 

2022-10-11 18:19:15,134 - INFO] EWAP_eth dataset : average bpp : 0.116874, average psnr : 36.594159, average msssim: 0.992202

2022-10-11 18:20:28,330 - INFO] global step 0 : 

2022-10-11 18:20:28,330 - INFO] EWAP_eth dataset : average bpp : 0.117992, average psnr : 36.834207, average msssim: 0.991652

2022-10-11 18:21:42,138 - INFO] global step 0 : 

2022-10-11 18:21:42,139 - INFO] EWAP_eth dataset : average bpp : 0.122320, average psnr : 36.620708, average msssim: 0.991979

2022-10-11 18:22:56,060 - INFO] global step 0 : 

2022-10-11 18:22:56,061 - INFO] EWAP_eth dataset : average bpp : 0.120647, average psnr : 36.718878, average msssim: 0.991639

2022-10-11 18:26:04,532 - INFO] DVC training
2022-10-11 18:26:04,532 - INFO] config : 
2022-10-11 18:26:04,533 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 18:28:11,204 - INFO] global step 0 : 

2022-10-11 18:28:11,205 - INFO] EWAP_eth dataset : average bpp : 0.245950, average psnr : 33.606285, average msssim: 0.987388

2022-10-11 18:30:20,634 - INFO] global step 0 : 

2022-10-11 18:30:20,635 - INFO] EWAP_eth dataset : average bpp : 0.157877, average psnr : 35.171138, average msssim: 0.987516

2022-10-11 18:32:04,836 - INFO] global step 0 : 

2022-10-11 18:32:04,837 - INFO] EWAP_eth dataset : average bpp : 0.139911, average psnr : 35.850249, average msssim: 0.986748

2022-10-11 18:32:19,800 - INFO] DVC training
2022-10-11 18:32:19,801 - INFO] config : 
2022-10-11 18:32:19,802 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-11 18:33:40,937 - INFO] global step 0 : 

2022-10-11 18:33:40,938 - INFO] EWAP_eth dataset : average bpp : 0.264976, average psnr : 34.310855, average msssim: 0.996613

2022-10-11 18:34:58,128 - INFO] global step 0 : 

2022-10-11 18:34:58,129 - INFO] EWAP_eth dataset : average bpp : 0.273440, average psnr : 33.888939, average msssim: 0.996343

2022-10-11 18:35:09,126 - INFO] global step 0 : 

2022-10-11 18:35:09,127 - INFO] EWAP_eth dataset : average bpp : 0.136688, average psnr : 35.572844, average msssim: 0.986908

2022-10-11 18:35:43,837 - INFO] global step 0 : 

2022-10-11 18:35:43,838 - INFO] EWAP_eth dataset : average bpp : 0.269338, average psnr : 34.202837, average msssim: 0.996621

2022-10-11 18:36:52,145 - INFO] global step 0 : 

2022-10-11 18:36:52,146 - INFO] EWAP_eth dataset : average bpp : 0.269819, average psnr : 34.343818, average msssim: 0.996283

2022-10-11 18:38:11,950 - INFO] global step 0 : 

2022-10-11 18:38:11,951 - INFO] EWAP_eth dataset : average bpp : 0.308637, average psnr : 32.713564, average msssim: 0.996190

2022-10-11 18:38:30,750 - INFO] global step 0 : 

2022-10-11 18:38:30,751 - INFO] EWAP_eth dataset : average bpp : 0.190980, average psnr : 33.837255, average msssim: 0.988665

2022-10-11 18:39:03,739 - INFO] global step 0 : 

2022-10-11 18:39:03,740 - INFO] EWAP_eth dataset : average bpp : 0.264171, average psnr : 34.449894, average msssim: 0.996684

2022-10-11 18:40:46,546 - INFO] global step 0 : 

2022-10-11 18:40:46,547 - INFO] EWAP_eth dataset : average bpp : 0.266113, average psnr : 34.256831, average msssim: 0.996652

2022-10-11 18:42:08,025 - INFO] global step 0 : 

2022-10-11 18:42:08,027 - INFO] EWAP_eth dataset : average bpp : 0.298315, average psnr : 32.657083, average msssim: 0.996170

2022-10-11 18:42:20,847 - INFO] global step 0 : 

2022-10-11 18:42:20,848 - INFO] EWAP_eth dataset : average bpp : 0.156778, average psnr : 35.599135, average msssim: 0.987142

2022-10-11 18:42:53,626 - INFO] global step 0 : 

2022-10-11 18:42:53,627 - INFO] EWAP_eth dataset : average bpp : 0.287471, average psnr : 33.227608, average msssim: 0.996556

2022-10-11 18:43:57,246 - INFO] global step 0 : 

2022-10-11 18:43:57,247 - INFO] EWAP_eth dataset : average bpp : 0.292967, average psnr : 33.314489, average msssim: 0.996464

2022-10-11 18:45:01,455 - INFO] global step 0 : 

2022-10-11 18:45:01,456 - INFO] EWAP_eth dataset : average bpp : 0.277797, average psnr : 34.026589, average msssim: 0.996255

2022-10-11 18:45:26,033 - INFO] global step 0 : 

2022-10-11 18:45:26,034 - INFO] EWAP_eth dataset : average bpp : 0.147527, average psnr : 35.937608, average msssim: 0.986731

2022-10-11 18:45:45,629 - INFO] global step 0 : 

2022-10-11 18:45:45,629 - INFO] EWAP_eth dataset : average bpp : 0.301478, average psnr : 32.620970, average msssim: 0.996178

2022-10-11 18:46:48,939 - INFO] global step 0 : 

2022-10-11 18:46:48,940 - INFO] EWAP_eth dataset : average bpp : 0.276280, average psnr : 33.803640, average msssim: 0.996253

2022-10-11 18:47:53,353 - INFO] global step 0 : 

2022-10-11 18:47:53,354 - INFO] EWAP_eth dataset : average bpp : 0.294938, average psnr : 33.162957, average msssim: 0.996285

2022-10-11 18:48:34,127 - INFO] global step 0 : 

2022-10-11 18:48:34,127 - INFO] EWAP_eth dataset : average bpp : 0.200006, average psnr : 33.944325, average msssim: 0.988443

2022-10-11 18:48:46,240 - INFO] global step 0 : 

2022-10-11 18:48:46,240 - INFO] EWAP_eth dataset : average bpp : 0.336518, average psnr : 31.419590, average msssim: 0.995808

2022-10-11 18:49:45,057 - INFO] global step 0 : 

2022-10-11 18:49:45,058 - INFO] EWAP_eth dataset : average bpp : 0.311152, average psnr : 32.487698, average msssim: 0.995977

2022-10-11 18:50:47,935 - INFO] global step 0 : 

2022-10-11 18:50:47,936 - INFO] EWAP_eth dataset : average bpp : 0.323303, average psnr : 31.914605, average msssim: 0.995931

2022-10-11 18:51:41,126 - INFO] global step 0 : 

2022-10-11 18:51:41,127 - INFO] EWAP_eth dataset : average bpp : 0.161841, average psnr : 35.537929, average msssim: 0.986835

2022-10-11 18:51:44,849 - INFO] global step 0 : 

2022-10-11 18:51:44,849 - INFO] EWAP_eth dataset : average bpp : 0.298697, average psnr : 32.963853, average msssim: 0.996407

2022-10-11 18:52:32,449 - INFO] global step 0 : 

2022-10-11 18:52:32,449 - INFO] EWAP_eth dataset : average bpp : 0.319960, average psnr : 31.751758, average msssim: 0.995854

2022-10-11 18:53:31,374 - INFO] global step 0 : 

2022-10-11 18:53:31,374 - INFO] EWAP_eth dataset : average bpp : 0.309921, average psnr : 32.659813, average msssim: 0.996035

2022-10-11 18:54:23,983 - INFO] global step 0 : 

2022-10-11 18:54:23,984 - INFO] EWAP_eth dataset : average bpp : 0.308288, average psnr : 32.479422, average msssim: 0.995885

2022-10-11 18:54:37,523 - INFO] global step 0 : 

2022-10-11 18:54:37,524 - INFO] EWAP_eth dataset : average bpp : 0.142207, average psnr : 35.910841, average msssim: 0.986484

2022-10-11 18:54:55,542 - INFO] global step 0 : 

2022-10-11 18:54:55,542 - INFO] EWAP_eth dataset : average bpp : 0.300270, average psnr : 32.684686, average msssim: 0.996372

2022-10-11 18:55:25,839 - INFO] global step 0 : 

2022-10-11 18:55:25,840 - INFO] EWAP_eth dataset : average bpp : 0.297016, average psnr : 33.127950, average msssim: 0.996232

2022-10-11 18:55:55,513 - INFO] global step 0 : 

2022-10-11 18:55:55,514 - INFO] EWAP_eth dataset : average bpp : 0.331747, average psnr : 32.247769, average msssim: 0.995974

2022-10-11 18:56:25,232 - INFO] global step 0 : 

2022-10-11 18:56:25,232 - INFO] EWAP_eth dataset : average bpp : 0.296001, average psnr : 32.852204, average msssim: 0.996158

2022-10-12 09:45:27,541 - INFO] DVC training
2022-10-12 09:45:27,541 - INFO] config : 
2022-10-12 09:45:27,547 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-12 09:46:30,263 - INFO] global step 0 : 

2022-10-12 09:46:30,264 - INFO] EWAP_eth dataset : average bpp : 0.292616, average psnr : 30.501508, average msssim: 0.992045

2022-10-12 09:47:23,243 - INFO] global step 0 : 

2022-10-12 09:47:23,244 - INFO] EWAP_eth dataset : average bpp : 0.300032, average psnr : 30.326894, average msssim: 0.992050

2022-10-12 09:48:18,658 - INFO] global step 0 : 

2022-10-12 09:48:18,659 - INFO] EWAP_eth dataset : average bpp : 0.297221, average psnr : 30.453224, average msssim: 0.992217

2022-10-12 09:49:53,934 - INFO] global step 0 : 

2022-10-12 09:49:53,935 - INFO] EWAP_eth dataset : average bpp : 0.297008, average psnr : 30.542819, average msssim: 0.991814

2022-10-12 09:51:30,855 - INFO] global step 0 : 

2022-10-12 09:51:30,856 - INFO] EWAP_eth dataset : average bpp : 0.335015, average psnr : 29.814368, average msssim: 0.992028

2022-10-12 09:52:09,649 - INFO] global step 0 : 

2022-10-12 09:52:09,649 - INFO] EWAP_eth dataset : average bpp : 0.291462, average psnr : 30.489074, average msssim: 0.992215

2022-10-12 09:52:42,533 - INFO] global step 0 : 

2022-10-12 09:52:42,534 - INFO] EWAP_eth dataset : average bpp : 0.293857, average psnr : 30.378221, average msssim: 0.992315

2022-10-12 09:53:14,140 - INFO] global step 0 : 

2022-10-12 09:53:14,140 - INFO] EWAP_eth dataset : average bpp : 0.326487, average psnr : 29.775562, average msssim: 0.991933

2022-10-12 09:53:46,270 - INFO] global step 0 : 

2022-10-12 09:53:46,271 - INFO] EWAP_eth dataset : average bpp : 0.315406, average psnr : 29.974654, average msssim: 0.992247

2022-10-12 09:54:17,028 - INFO] global step 0 : 

2022-10-12 09:54:17,028 - INFO] EWAP_eth dataset : average bpp : 0.322158, average psnr : 29.956814, average msssim: 0.992257

2022-10-12 09:55:01,443 - INFO] global step 0 : 

2022-10-12 09:55:01,444 - INFO] EWAP_eth dataset : average bpp : 0.306298, average psnr : 30.246364, average msssim: 0.991781

2022-10-12 09:55:50,245 - INFO] global step 0 : 

2022-10-12 09:55:50,246 - INFO] EWAP_eth dataset : average bpp : 0.331273, average psnr : 29.530923, average msssim: 0.991994

2022-10-12 09:56:38,236 - INFO] global step 0 : 

2022-10-12 09:56:38,237 - INFO] EWAP_eth dataset : average bpp : 0.306123, average psnr : 30.031948, average msssim: 0.991578

2022-10-12 09:57:23,751 - INFO] global step 0 : 

2022-10-12 09:57:23,752 - INFO] EWAP_eth dataset : average bpp : 0.326692, average psnr : 29.655580, average msssim: 0.991677

2022-10-12 09:58:12,055 - INFO] global step 0 : 

2022-10-12 09:58:12,056 - INFO] EWAP_eth dataset : average bpp : 0.366882, average psnr : 28.901461, average msssim: 0.991803

2022-10-12 09:58:58,128 - INFO] global step 0 : 

2022-10-12 09:58:58,129 - INFO] EWAP_eth dataset : average bpp : 0.342917, average psnr : 29.284555, average msssim: 0.991800

2022-10-12 09:59:41,529 - INFO] global step 0 : 

2022-10-12 09:59:41,530 - INFO] EWAP_eth dataset : average bpp : 0.355627, average psnr : 28.996272, average msssim: 0.991905

2022-10-12 10:00:15,843 - INFO] global step 0 : 

2022-10-12 10:00:15,843 - INFO] EWAP_eth dataset : average bpp : 0.331816, average psnr : 29.423800, average msssim: 0.991972

2022-10-12 10:00:44,703 - INFO] global step 0 : 

2022-10-12 10:00:44,703 - INFO] EWAP_eth dataset : average bpp : 0.352673, average psnr : 28.878617, average msssim: 0.991471

2022-10-12 10:01:12,213 - INFO] global step 0 : 

2022-10-12 10:01:12,213 - INFO] EWAP_eth dataset : average bpp : 0.343210, average psnr : 29.303165, average msssim: 0.991527

2022-10-12 10:01:39,663 - INFO] global step 0 : 

2022-10-12 10:01:39,664 - INFO] EWAP_eth dataset : average bpp : 0.340125, average psnr : 29.341166, average msssim: 0.991356

2022-10-12 10:02:07,157 - INFO] global step 0 : 

2022-10-12 10:02:07,157 - INFO] EWAP_eth dataset : average bpp : 0.331605, average psnr : 29.337360, average msssim: 0.991800

2022-10-12 10:02:34,426 - INFO] global step 0 : 

2022-10-12 10:02:34,427 - INFO] EWAP_eth dataset : average bpp : 0.328604, average psnr : 29.564498, average msssim: 0.991580

2022-10-12 10:03:03,037 - INFO] global step 0 : 

2022-10-12 10:03:03,037 - INFO] EWAP_eth dataset : average bpp : 0.363242, average psnr : 29.170129, average msssim: 0.991645

2022-10-12 10:03:45,840 - INFO] global step 0 : 

2022-10-12 10:03:45,841 - INFO] EWAP_eth dataset : average bpp : 0.326681, average psnr : 29.446988, average msssim: 0.991445

2022-10-12 10:09:26,599 - INFO] DVC training
2022-10-12 10:09:26,599 - INFO] config : 
2022-10-12 10:09:26,600 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-12 10:11:14,244 - INFO] global step 0 : 

2022-10-12 10:11:14,245 - INFO] EWAP_eth dataset : average bpp : 0.441587, average psnr : 31.024856, average msssim: 0.993030

2022-10-12 10:11:53,240 - INFO] global step 0 : 

2022-10-12 10:11:53,240 - INFO] EWAP_eth dataset : average bpp : 0.444528, average psnr : 30.938582, average msssim: 0.993184

2022-10-12 10:12:33,063 - INFO] global step 0 : 

2022-10-12 10:12:33,063 - INFO] EWAP_eth dataset : average bpp : 0.445415, average psnr : 30.985789, average msssim: 0.993181

2022-10-12 10:13:27,343 - INFO] global step 0 : 

2022-10-12 10:13:27,344 - INFO] EWAP_eth dataset : average bpp : 0.441450, average psnr : 31.142554, average msssim: 0.993006

2022-10-12 10:14:20,242 - INFO] global step 0 : 

2022-10-12 10:14:20,243 - INFO] EWAP_eth dataset : average bpp : 0.484811, average psnr : 30.461179, average msssim: 0.993192

2022-10-12 10:15:14,224 - INFO] global step 0 : 

2022-10-12 10:15:14,224 - INFO] EWAP_eth dataset : average bpp : 0.441436, average psnr : 31.006905, average msssim: 0.993184

2022-10-12 10:16:07,740 - INFO] global step 0 : 

2022-10-12 10:16:07,740 - INFO] EWAP_eth dataset : average bpp : 0.442918, average psnr : 30.892127, average msssim: 0.993256

2022-10-12 10:17:00,356 - INFO] global step 0 : 

2022-10-12 10:17:00,356 - INFO] EWAP_eth dataset : average bpp : 0.473195, average psnr : 30.423299, average msssim: 0.993115

2022-10-12 10:17:57,147 - INFO] global step 0 : 

2022-10-12 10:17:57,148 - INFO] EWAP_eth dataset : average bpp : 0.465932, average psnr : 30.543869, average msssim: 0.993209

2022-10-12 10:18:47,447 - INFO] global step 0 : 

2022-10-12 10:18:47,447 - INFO] EWAP_eth dataset : average bpp : 0.471653, average psnr : 30.507664, average msssim: 0.993241

2022-10-12 10:19:27,358 - INFO] global step 0 : 

2022-10-12 10:19:27,358 - INFO] EWAP_eth dataset : average bpp : 0.453540, average psnr : 30.819563, average msssim: 0.992946

2022-10-12 10:20:05,649 - INFO] global step 0 : 

2022-10-12 10:20:05,649 - INFO] EWAP_eth dataset : average bpp : 0.479889, average psnr : 30.170026, average msssim: 0.993147

2022-10-12 10:20:45,140 - INFO] global step 0 : 

2022-10-12 10:20:45,141 - INFO] EWAP_eth dataset : average bpp : 0.453685, average psnr : 30.597494, average msssim: 0.992760

2022-10-12 10:21:21,547 - INFO] global step 0 : 

2022-10-12 10:21:21,548 - INFO] EWAP_eth dataset : average bpp : 0.484608, average psnr : 30.187916, average msssim: 0.992750

2022-10-12 10:22:06,255 - INFO] global step 0 : 

2022-10-12 10:22:06,255 - INFO] EWAP_eth dataset : average bpp : 0.521951, average psnr : 29.589150, average msssim: 0.993050

2022-10-12 10:22:59,844 - INFO] global step 0 : 

2022-10-12 10:22:59,844 - INFO] EWAP_eth dataset : average bpp : 0.498070, average psnr : 29.920145, average msssim: 0.993039

2022-10-12 10:23:53,245 - INFO] global step 0 : 

2022-10-12 10:23:53,246 - INFO] EWAP_eth dataset : average bpp : 0.509293, average psnr : 29.640937, average msssim: 0.993114

2022-10-12 10:24:44,735 - INFO] global step 0 : 

2022-10-12 10:24:44,736 - INFO] EWAP_eth dataset : average bpp : 0.491665, average psnr : 29.930252, average msssim: 0.992997

2022-10-12 10:25:41,056 - INFO] global step 0 : 

2022-10-12 10:25:41,057 - INFO] EWAP_eth dataset : average bpp : 0.508061, average psnr : 29.529014, average msssim: 0.992749

2022-10-12 10:26:36,639 - INFO] global step 0 : 

2022-10-12 10:26:36,640 - INFO] EWAP_eth dataset : average bpp : 0.496668, average psnr : 29.897019, average msssim: 0.992737

2022-10-12 10:27:31,457 - INFO] global step 0 : 

2022-10-12 10:27:31,457 - INFO] EWAP_eth dataset : average bpp : 0.495577, average psnr : 29.957037, average msssim: 0.992631

2022-10-12 10:28:12,844 - INFO] global step 0 : 

2022-10-12 10:28:12,844 - INFO] EWAP_eth dataset : average bpp : 0.489903, average psnr : 29.861153, average msssim: 0.992822

2022-10-12 10:28:50,956 - INFO] global step 0 : 

2022-10-12 10:28:50,956 - INFO] EWAP_eth dataset : average bpp : 0.487136, average psnr : 30.112589, average msssim: 0.992673

2022-10-12 10:29:29,234 - INFO] global step 0 : 

2022-10-12 10:29:29,234 - INFO] EWAP_eth dataset : average bpp : 0.520628, average psnr : 29.748631, average msssim: 0.992759

2022-10-12 10:30:05,756 - INFO] global step 0 : 

2022-10-12 10:30:05,756 - INFO] EWAP_eth dataset : average bpp : 0.485394, average psnr : 29.997791, average msssim: 0.992566

2022-10-23 15:52:38,437 - INFO] DVC training
2022-10-23 15:52:38,438 - INFO] config : 
2022-10-23 15:52:38,441 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 15:53:07,544 - INFO] DVC training
2022-10-23 15:53:07,544 - INFO] config : 
2022-10-23 15:53:07,545 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 15:53:42,735 - INFO] DVC training
2022-10-23 15:53:42,735 - INFO] config : 
2022-10-23 15:53:42,742 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 15:55:36,862 - INFO] DVC training
2022-10-23 15:55:36,863 - INFO] config : 
2022-10-23 15:55:36,869 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 15:56:03,850 - INFO] DVC training
2022-10-23 15:56:03,850 - INFO] config : 
2022-10-23 15:56:03,851 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:05:05,408 - INFO] DVC training
2022-10-23 16:05:05,408 - INFO] config : 
2022-10-23 16:05:05,414 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:06:15,885 - INFO] DVC training
2022-10-23 16:06:15,885 - INFO] config : 
2022-10-23 16:06:15,886 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:07:10,541 - INFO] global step 0 : 

2022-10-23 16:07:10,541 - INFO] EWAP_eth dataset : average bpp : 0.117993, average psnr : 36.834192, average msssim: 0.991652

2022-10-23 16:07:58,972 - INFO] global step 0 : 

2022-10-23 16:07:58,972 - INFO] EWAP_eth dataset : average bpp : 0.117992, average psnr : 36.834198, average msssim: 0.991652

2022-10-23 16:15:00,833 - INFO] DVC training
2022-10-23 16:15:00,833 - INFO] config : 
2022-10-23 16:15:00,834 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 200000,
    "train_lambda": 512,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:16:16,504 - INFO] global step 0 : 

2022-10-23 16:16:16,504 - INFO] EWAP_eth dataset : average bpp : 0.118695, average psnr : 35.353444, average msssim: 0.989063

2022-10-23 16:17:41,040 - INFO] DVC training
2022-10-23 16:17:41,040 - INFO] config : 
2022-10-23 16:17:41,047 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:21:06,831 - INFO] DVC training
2022-10-23 16:21:06,831 - INFO] config : 
2022-10-23 16:21:06,838 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:22:56,412 - INFO] Train Epoch : 00 Loss:	 0.017132	 lr:1e-05
2022-10-23 16:24:40,860 - INFO] Train Epoch : 01 Loss:	 0.016289	 lr:1e-05
2022-10-23 16:26:04,314 - INFO] DVC training
2022-10-23 16:26:04,314 - INFO] config : 
2022-10-23 16:26:04,315 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:26:25,492 - INFO] Train Epoch : 02 Loss:	 0.018565	 lr:1e-05
2022-10-23 16:27:19,262 - INFO] global step 748 : 

2022-10-23 16:27:19,262 - INFO] EWAP_eth dataset : average bpp : 0.106749, average psnr : 36.226199, average msssim: 0.989840

2022-10-23 16:28:09,835 - INFO] Train Epoch : 03 Loss:	 0.017545	 lr:1e-05
2022-10-23 16:29:54,254 - INFO] Train Epoch : 04 Loss:	 0.017549	 lr:1e-05
2022-10-23 16:31:38,718 - INFO] Train Epoch : 05 Loss:	 0.015825	 lr:1e-05
2022-10-23 16:33:22,885 - INFO] Train Epoch : 06 Loss:	 0.015484	 lr:1e-05
2022-10-23 16:34:44,718 - INFO] DVC training
2022-10-23 16:34:44,719 - INFO] config : 
2022-10-23 16:34:44,726 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:35:07,095 - INFO] Train Epoch : 07 Loss:	 0.019010	 lr:1e-05
2022-10-23 16:36:51,845 - INFO] Train Epoch : 08 Loss:	 0.014612	 lr:1e-05
2022-10-23 16:36:58,578 - INFO] global step 2618 : 

2022-10-23 16:36:58,579 - INFO] EWAP_eth dataset : average bpp : 0.102412, average psnr : 36.350395, average msssim: 0.989953

2022-10-23 16:38:35,908 - INFO] Train Epoch : 09 Loss:	 0.016285	 lr:1e-05
2022-10-23 16:40:20,631 - INFO] Train Epoch : 10 Loss:	 0.020462	 lr:1e-05
2022-10-23 16:40:55,871 - INFO] DVC training
2022-10-23 16:40:55,872 - INFO] config : 
2022-10-23 16:40:55,877 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:42:05,718 - INFO] Train Epoch : 11 Loss:	 0.014939	 lr:1e-05
2022-10-23 16:43:11,134 - INFO] global step 2618 : 

2022-10-23 16:43:11,137 - INFO] EWAP_eth dataset : average bpp : 0.102413, average psnr : 36.350439, average msssim: 0.989953

2022-10-23 16:43:43,537 - INFO] DVC training
2022-10-23 16:43:43,537 - INFO] config : 
2022-10-23 16:43:43,539 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:43:50,486 - INFO] Train Epoch : 12 Loss:	 0.019577	 lr:1e-05
2022-10-23 16:45:32,112 - INFO] global step 2618 : 

2022-10-23 16:45:32,113 - INFO] EWAP_eth dataset : average bpp : 0.102122, average psnr : 39.413372, average msssim: 0.998089

2022-10-23 16:45:35,349 - INFO] Train Epoch : 13 Loss:	 0.020524	 lr:1e-05
2022-10-23 16:47:20,173 - INFO] Train Epoch : 14 Loss:	 0.019562	 lr:1e-05
2022-10-23 16:47:52,744 - INFO] DVC training
2022-10-23 16:47:52,744 - INFO] config : 
2022-10-23 16:47:52,751 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:49:04,582 - INFO] Train Epoch : 15 Loss:	 0.023752	 lr:1e-05
2022-10-23 16:50:05,087 - INFO] global step 2618 : 

2022-10-23 16:50:05,089 - INFO] EWAP_eth dataset : average bpp : 0.102117, average psnr : 39.135613, average msssim: 0.997540

2022-10-23 16:50:50,282 - INFO] Train Epoch : 16 Loss:	 0.014754	 lr:1e-05
2022-10-23 16:50:55,585 - INFO] DVC training
2022-10-23 16:50:55,586 - INFO] config : 
2022-10-23 16:50:55,587 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:52:34,867 - INFO] Train Epoch : 17 Loss:	 0.020007	 lr:1e-05
2022-10-23 16:53:08,223 - INFO] global step 2618 : 

2022-10-23 16:53:08,223 - INFO] EWAP_eth dataset : average bpp : 0.102195, average psnr : 38.359580, average msssim: 0.995885

2022-10-23 16:53:49,653 - INFO] DVC training
2022-10-23 16:53:49,654 - INFO] config : 
2022-10-23 16:53:49,655 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 16:54:19,705 - INFO] Train Epoch : 18 Loss:	 0.014635	 lr:1e-05
2022-10-23 17:15:32,677 - INFO] DVC training
2022-10-23 17:15:32,677 - INFO] config : 
2022-10-23 17:15:32,678 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:17:45,603 - INFO] DVC training
2022-10-23 17:17:45,603 - INFO] config : 
2022-10-23 17:17:45,604 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:18:33,343 - INFO] DVC training
2022-10-23 17:18:33,344 - INFO] config : 
2022-10-23 17:18:33,345 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:19:42,485 - INFO] DVC training
2022-10-23 17:19:42,485 - INFO] config : 
2022-10-23 17:19:42,486 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:20:37,914 - INFO] DVC training
2022-10-23 17:20:37,914 - INFO] config : 
2022-10-23 17:20:37,915 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:21:27,655 - INFO] DVC training
2022-10-23 17:21:27,656 - INFO] config : 
2022-10-23 17:21:27,657 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:22:41,289 - INFO] DVC training
2022-10-23 17:22:41,290 - INFO] config : 
2022-10-23 17:22:41,291 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:23:34,947 - INFO] DVC training
2022-10-23 17:23:34,947 - INFO] config : 
2022-10-23 17:23:34,948 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:24:18,740 - INFO] DVC training
2022-10-23 17:24:18,741 - INFO] config : 
2022-10-23 17:24:18,742 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:25:19,072 - INFO] DVC training
2022-10-23 17:25:19,072 - INFO] config : 
2022-10-23 17:25:19,073 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:26:13,298 - INFO] DVC training
2022-10-23 17:26:13,298 - INFO] config : 
2022-10-23 17:26:13,300 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:26:49,425 - INFO] DVC training
2022-10-23 17:26:49,426 - INFO] config : 
2022-10-23 17:26:49,427 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:27:35,921 - INFO] DVC training
2022-10-23 17:27:35,921 - INFO] config : 
2022-10-23 17:27:35,922 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:31:16,194 - INFO] DVC training
2022-10-23 17:31:16,195 - INFO] config : 
2022-10-23 17:31:16,196 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:34:28,195 - INFO] DVC training
2022-10-23 17:34:28,196 - INFO] config : 
2022-10-23 17:34:28,197 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:37:41,752 - INFO] DVC training
2022-10-23 17:37:41,752 - INFO] config : 
2022-10-23 17:37:41,754 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:40:32,929 - INFO] Train Epoch : 00 Loss:	 0.014179	 lr:1e-05
2022-10-23 17:42:19,055 - INFO] Train Epoch : 01 Loss:	 0.014030	 lr:1e-05
2022-10-23 17:44:04,186 - INFO] Train Epoch : 02 Loss:	 0.014530	 lr:1e-05
2022-10-23 17:45:06,516 - INFO] DVC training
2022-10-23 17:45:06,517 - INFO] config : 
2022-10-23 17:45:06,518 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-23 17:46:55,307 - INFO] Train Epoch : 00 Loss:	 0.018321	 lr:1e-05
2022-10-23 17:48:51,352 - INFO] Train Epoch : 01 Loss:	 0.018739	 lr:1e-05
2022-10-23 17:50:44,169 - INFO] Train Epoch : 02 Loss:	 0.015365	 lr:1e-05
2022-10-23 17:52:33,474 - INFO] Train Epoch : 03 Loss:	 0.018093	 lr:1e-05
2022-10-23 17:54:24,024 - INFO] Train Epoch : 04 Loss:	 0.021078	 lr:1e-05
2022-10-23 17:56:17,467 - INFO] Train Epoch : 05 Loss:	 0.015325	 lr:1e-05
2022-10-23 17:58:13,930 - INFO] Train Epoch : 06 Loss:	 0.016216	 lr:1e-05
2022-10-23 18:00:08,145 - INFO] Train Epoch : 07 Loss:	 0.021983	 lr:1e-05
2022-10-23 18:02:02,923 - INFO] Train Epoch : 08 Loss:	 0.023225	 lr:1e-05
2022-10-23 18:03:58,295 - INFO] Train Epoch : 09 Loss:	 0.019123	 lr:1e-05
2022-10-23 18:05:54,439 - INFO] Train Epoch : 10 Loss:	 0.014031	 lr:1e-05
2022-10-23 18:07:49,724 - INFO] Train Epoch : 11 Loss:	 0.017967	 lr:1e-05
2022-10-23 18:09:44,608 - INFO] Train Epoch : 12 Loss:	 0.015798	 lr:1e-05
2022-10-23 18:11:39,579 - INFO] Train Epoch : 13 Loss:	 0.012995	 lr:1e-05
2022-10-23 18:13:35,014 - INFO] Train Epoch : 14 Loss:	 0.016923	 lr:1e-05
2022-10-23 18:15:30,735 - INFO] Train Epoch : 15 Loss:	 0.014599	 lr:1e-05
2022-10-23 18:17:27,892 - INFO] Train Epoch : 16 Loss:	 0.017579	 lr:1e-05
2022-10-23 18:19:24,693 - INFO] Train Epoch : 17 Loss:	 0.018319	 lr:1e-05
2022-10-23 18:21:24,110 - INFO] Train Epoch : 18 Loss:	 0.019284	 lr:1e-05
2022-10-23 18:23:22,086 - INFO] Train Epoch : 19 Loss:	 0.025508	 lr:1e-05
2022-10-23 18:25:24,650 - INFO] Train Epoch : 20 Loss:	 0.018218	 lr:1e-05
2022-10-23 18:27:20,699 - INFO] Train Epoch : 21 Loss:	 0.018632	 lr:1e-05
2022-10-23 18:29:12,253 - INFO] Train Epoch : 22 Loss:	 0.017207	 lr:1e-05
2022-10-23 18:31:02,960 - INFO] Train Epoch : 23 Loss:	 0.019299	 lr:1e-05
2022-10-23 18:32:53,858 - INFO] Train Epoch : 24 Loss:	 0.018757	 lr:1e-05
2022-10-23 18:34:41,405 - INFO] Train Epoch : 25 Loss:	 0.019115	 lr:1e-05
2022-10-23 18:36:29,984 - INFO] Train Epoch : 26 Loss:	 0.016388	 lr:1e-05
2022-10-23 18:38:18,890 - INFO] Train Epoch : 27 Loss:	 0.015618	 lr:1e-05
2022-10-23 18:40:16,244 - INFO] Train Epoch : 28 Loss:	 0.018227	 lr:1e-05
2022-10-23 18:42:03,598 - INFO] Train Epoch : 29 Loss:	 0.018011	 lr:1e-05
2022-10-23 18:43:52,233 - INFO] Train Epoch : 30 Loss:	 0.017258	 lr:1e-05
2022-10-23 18:45:42,686 - INFO] Train Epoch : 31 Loss:	 0.019228	 lr:1e-05
2022-10-23 18:47:32,476 - INFO] Train Epoch : 32 Loss:	 0.015048	 lr:1e-05
2022-10-23 18:49:24,220 - INFO] Train Epoch : 33 Loss:	 0.015440	 lr:1e-05
2022-10-23 18:51:20,392 - INFO] Train Epoch : 34 Loss:	 0.024469	 lr:1e-05
2022-10-23 18:53:14,220 - INFO] Train Epoch : 35 Loss:	 0.016350	 lr:1e-05
2022-10-23 18:55:05,310 - INFO] Train Epoch : 36 Loss:	 0.016586	 lr:1e-05
2022-10-23 18:57:02,549 - INFO] Train Epoch : 37 Loss:	 0.026864	 lr:1e-05
2022-10-23 18:58:55,308 - INFO] Train Epoch : 38 Loss:	 0.016861	 lr:1e-05
2022-10-23 19:00:44,601 - INFO] Train Epoch : 39 Loss:	 0.015498	 lr:1e-05
2022-10-23 19:02:40,725 - INFO] Train Epoch : 40 Loss:	 0.015623	 lr:1e-05
2022-10-23 19:04:30,784 - INFO] Train Epoch : 41 Loss:	 0.013949	 lr:1e-05
2022-10-23 19:06:22,890 - INFO] Train Epoch : 42 Loss:	 0.012396	 lr:1e-05
2022-10-23 19:08:11,597 - INFO] Train Epoch : 43 Loss:	 0.017011	 lr:1e-05
2022-10-23 19:10:01,261 - INFO] Train Epoch : 44 Loss:	 0.022591	 lr:1e-05
2022-10-23 19:11:50,649 - INFO] Train Epoch : 45 Loss:	 0.016399	 lr:1e-05
2022-10-23 19:13:40,755 - INFO] Train Epoch : 46 Loss:	 0.017281	 lr:1e-05
2022-10-23 19:15:29,708 - INFO] Train Epoch : 47 Loss:	 0.016736	 lr:1e-05
2022-10-23 19:17:18,645 - INFO] Train Epoch : 48 Loss:	 0.016380	 lr:1e-05
2022-10-23 19:19:06,589 - INFO] Train Epoch : 49 Loss:	 0.024759	 lr:1e-05
2022-10-23 19:20:56,623 - INFO] Train Epoch : 50 Loss:	 0.014361	 lr:1e-05
2022-10-23 19:22:45,619 - INFO] Train Epoch : 51 Loss:	 0.017054	 lr:1e-05
2022-10-23 19:24:33,328 - INFO] Train Epoch : 52 Loss:	 0.018873	 lr:1e-05
2022-10-23 19:26:20,546 - INFO] Train Epoch : 53 Loss:	 0.020008	 lr:1e-05
2022-10-23 19:28:06,271 - INFO] Train Epoch : 54 Loss:	 0.015814	 lr:1e-05
2022-10-23 19:29:51,905 - INFO] Train Epoch : 55 Loss:	 0.023794	 lr:1e-05
2022-10-24 09:37:24,427 - INFO] DVC training
2022-10-24 09:37:24,427 - INFO] config : 
2022-10-24 09:37:24,429 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:39:23,341 - INFO] DVC training
2022-10-24 09:39:23,341 - INFO] config : 
2022-10-24 09:39:23,343 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:40:27,932 - INFO] global step 20272 : 

2022-10-24 09:40:27,932 - INFO] EWAP_eth dataset : average bpp : 0.100982, average psnr : 35.626607, average msssim: 0.988073

2022-10-24 09:45:21,030 - INFO] DVC training
2022-10-24 09:45:21,030 - INFO] config : 
2022-10-24 09:45:21,032 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:46:09,018 - INFO] DVC training
2022-10-24 09:46:09,018 - INFO] config : 
2022-10-24 09:46:09,019 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:46:55,841 - INFO] DVC training
2022-10-24 09:46:55,841 - INFO] config : 
2022-10-24 09:46:55,842 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:49:27,247 - INFO] DVC training
2022-10-24 09:49:27,247 - INFO] config : 
2022-10-24 09:49:27,248 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:50:32,740 - INFO] global step 20272 : 

2022-10-24 09:50:32,740 - INFO] EWAP_eth dataset : average bpp : 0.100812, average psnr : 36.050407, average msssim: 0.989599

2022-10-24 09:52:52,172 - INFO] DVC training
2022-10-24 09:52:52,172 - INFO] config : 
2022-10-24 09:52:52,173 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:55:44,566 - INFO] DVC training
2022-10-24 09:55:44,566 - INFO] config : 
2022-10-24 09:55:44,568 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:56:40,192 - INFO] DVC training
2022-10-24 09:56:40,192 - INFO] config : 
2022-10-24 09:56:40,193 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 09:57:46,652 - INFO] global step 20272 : 

2022-10-24 09:57:46,652 - INFO] EWAP_eth dataset : average bpp : 0.100448, average psnr : 36.336826, average msssim: 0.990770

2022-10-24 09:58:42,916 - INFO] DVC training
2022-10-24 09:58:42,916 - INFO] config : 
2022-10-24 09:58:42,917 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:00:26,032 - INFO] Train Epoch : 00 Loss:	 0.014506	 lr:1e-05
2022-10-24 10:02:05,946 - INFO] Train Epoch : 01 Loss:	 0.013338	 lr:1e-05
2022-10-24 10:03:45,884 - INFO] Train Epoch : 02 Loss:	 0.014466	 lr:1e-05
2022-10-24 10:05:25,759 - INFO] Train Epoch : 03 Loss:	 0.013948	 lr:1e-05
2022-10-24 10:07:05,574 - INFO] Train Epoch : 04 Loss:	 0.015661	 lr:1e-05
2022-10-24 10:08:45,187 - INFO] Train Epoch : 05 Loss:	 0.013270	 lr:1e-05
2022-10-24 10:10:24,179 - INFO] Train Epoch : 06 Loss:	 0.013188	 lr:1e-05
2022-10-24 10:11:33,243 - INFO] DVC training
2022-10-24 10:11:33,244 - INFO] config : 
2022-10-24 10:11:33,245 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:12:03,650 - INFO] Train Epoch : 07 Loss:	 0.012832	 lr:1e-05
2022-10-24 10:12:40,006 - INFO] global step 2534 : 

2022-10-24 10:12:40,007 - INFO] EWAP_eth dataset : average bpp : 0.104666, average psnr : 36.645677, average msssim: 0.991213

2022-10-24 10:13:43,943 - INFO] Train Epoch : 08 Loss:	 0.015192	 lr:1e-05
2022-10-24 10:15:23,797 - INFO] Train Epoch : 09 Loss:	 0.015508	 lr:1e-05
2022-10-24 10:17:03,561 - INFO] Train Epoch : 10 Loss:	 0.016953	 lr:1e-05
2022-10-24 10:18:42,956 - INFO] Train Epoch : 11 Loss:	 0.016129	 lr:1e-05
2022-10-24 10:19:38,489 - INFO] DVC training
2022-10-24 10:19:38,489 - INFO] config : 
2022-10-24 10:19:38,491 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:20:23,035 - INFO] Train Epoch : 12 Loss:	 0.013152	 lr:1e-05
2022-10-24 10:20:46,740 - INFO] global step 4344 : 

2022-10-24 10:20:46,741 - INFO] EWAP_eth dataset : average bpp : 0.104715, average psnr : 36.561728, average msssim: 0.991169

2022-10-24 10:22:03,035 - INFO] Train Epoch : 13 Loss:	 0.013878	 lr:1e-05
2022-10-24 10:22:41,140 - INFO] DVC training
2022-10-24 10:22:41,140 - INFO] config : 
2022-10-24 10:22:41,141 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:23:43,504 - INFO] Train Epoch : 14 Loss:	 0.014499	 lr:1e-05
2022-10-24 10:23:47,387 - INFO] global step 16456 : 

2022-10-24 10:23:47,388 - INFO] EWAP_eth dataset : average bpp : 0.093992, average psnr : 36.789447, average msssim: 0.990838

2022-10-24 10:25:25,761 - INFO] DVC training
2022-10-24 10:25:25,761 - INFO] config : 
2022-10-24 10:25:25,762 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:25:34,174 - INFO] Train Epoch : 15 Loss:	 0.012318	 lr:1e-05
2022-10-24 10:26:35,969 - INFO] global step 0 : 

2022-10-24 10:26:35,969 - INFO] EWAP_eth dataset : average bpp : 0.121092, average psnr : 35.969706, average msssim: 0.990928

2022-10-24 10:27:17,311 - INFO] Train Epoch : 16 Loss:	 0.013508	 lr:1e-05
2022-10-24 10:28:56,982 - INFO] Train Epoch : 17 Loss:	 0.011993	 lr:1e-05
2022-10-24 10:30:36,843 - INFO] Train Epoch : 18 Loss:	 0.013881	 lr:1e-05
2022-10-24 10:32:16,463 - INFO] Train Epoch : 19 Loss:	 0.016126	 lr:1e-05
2022-10-24 10:33:46,632 - INFO] DVC training
2022-10-24 10:33:46,632 - INFO] config : 
2022-10-24 10:33:46,633 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:33:56,584 - INFO] Train Epoch : 20 Loss:	 0.014130	 lr:1e-05
2022-10-24 10:34:55,634 - INFO] DVC training
2022-10-24 10:34:55,634 - INFO] config : 
2022-10-24 10:34:55,635 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:35:36,857 - INFO] Train Epoch : 21 Loss:	 0.012562	 lr:1e-05
2022-10-24 10:36:09,414 - INFO] DVC training
2022-10-24 10:36:09,414 - INFO] config : 
2022-10-24 10:36:09,415 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:37:15,661 - INFO] global step 16456 : 

2022-10-24 10:37:15,662 - INFO] EWAP_eth dataset : average bpp : 0.093972, average psnr : 36.792398, average msssim: 0.990852

2022-10-24 10:37:17,116 - INFO] Train Epoch : 22 Loss:	 0.012852	 lr:1e-05
2022-10-24 10:38:37,319 - INFO] DVC training
2022-10-24 10:38:37,320 - INFO] config : 
2022-10-24 10:38:37,321 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:38:57,242 - INFO] Train Epoch : 23 Loss:	 0.013334	 lr:1e-05
2022-10-24 10:39:45,848 - INFO] global step 16456 : 

2022-10-24 10:39:45,849 - INFO] EWAP_eth dataset : average bpp : 0.094105, average psnr : 36.658853, average msssim: 0.990344

2022-10-24 10:40:31,023 - INFO] DVC training
2022-10-24 10:40:31,023 - INFO] config : 
2022-10-24 10:40:31,025 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:40:37,316 - INFO] Train Epoch : 24 Loss:	 0.016626	 lr:1e-05
2022-10-24 10:41:39,358 - INFO] global step 16456 : 

2022-10-24 10:41:39,359 - INFO] EWAP_eth dataset : average bpp : 0.093749, average psnr : 36.426290, average msssim: 0.989971

2022-10-24 10:42:17,338 - INFO] Train Epoch : 25 Loss:	 0.011839	 lr:1e-05
2022-10-24 10:42:17,834 - INFO] DVC training
2022-10-24 10:42:17,834 - INFO] config : 
2022-10-24 10:42:17,835 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:43:26,603 - INFO] global step 16456 : 

2022-10-24 10:43:26,604 - INFO] EWAP_eth dataset : average bpp : 0.093681, average psnr : 36.724462, average msssim: 0.990904

2022-10-24 10:43:58,095 - INFO] Train Epoch : 26 Loss:	 0.012289	 lr:1e-05
2022-10-24 10:45:06,567 - INFO] DVC training
2022-10-24 10:45:06,568 - INFO] config : 
2022-10-24 10:45:06,569 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:45:39,659 - INFO] Train Epoch : 27 Loss:	 0.012177	 lr:1e-05
2022-10-24 10:46:17,519 - INFO] global step 16456 : 

2022-10-24 10:46:17,520 - INFO] EWAP_eth dataset : average bpp : 0.093681, average psnr : 36.725293, average msssim: 0.990904

2022-10-24 10:47:20,497 - INFO] Train Epoch : 28 Loss:	 0.013879	 lr:1e-05
2022-10-24 10:48:14,175 - INFO] DVC training
2022-10-24 10:48:14,175 - INFO] config : 
2022-10-24 10:48:14,176 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:49:21,699 - INFO] global step 10498 : 

2022-10-24 10:49:21,700 - INFO] EWAP_eth dataset : average bpp : 0.104483, average psnr : 36.197200, average msssim: 0.990827

2022-10-24 10:50:25,378 - INFO] DVC training
2022-10-24 10:50:25,378 - INFO] config : 
2022-10-24 10:50:25,379 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:51:33,367 - INFO] global step 10498 : 

2022-10-24 10:51:33,368 - INFO] EWAP_eth dataset : average bpp : 0.104661, average psnr : 36.403135, average msssim: 0.991048

2022-10-24 10:52:28,028 - INFO] DVC training
2022-10-24 10:52:28,029 - INFO] config : 
2022-10-24 10:52:28,030 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 10:54:12,770 - INFO] Train Epoch : 00 Loss:	 0.015025	 lr:1e-05
2022-10-24 10:55:53,540 - INFO] Train Epoch : 01 Loss:	 0.013530	 lr:1e-05
2022-10-24 10:57:34,391 - INFO] Train Epoch : 02 Loss:	 0.013231	 lr:1e-05
2022-10-24 10:59:15,236 - INFO] Train Epoch : 03 Loss:	 0.013402	 lr:1e-05
2022-10-24 10:59:48,501 - INFO] DVC training
2022-10-24 10:59:48,501 - INFO] config : 
2022-10-24 10:59:48,502 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 11:00:56,804 - INFO] Train Epoch : 04 Loss:	 0.018467	 lr:1e-05
2022-10-24 11:00:58,967 - INFO] global step 1448 : 

2022-10-24 11:00:58,967 - INFO] EWAP_eth dataset : average bpp : 0.105849, average psnr : 36.559381, average msssim: 0.990917

2022-10-24 11:02:38,014 - INFO] Train Epoch : 05 Loss:	 0.013362	 lr:1e-05
2022-10-24 11:04:18,694 - INFO] Train Epoch : 06 Loss:	 0.015361	 lr:1e-05
2022-10-24 11:05:59,393 - INFO] Train Epoch : 07 Loss:	 0.012979	 lr:1e-05
2022-10-24 11:07:40,368 - INFO] Train Epoch : 08 Loss:	 0.013863	 lr:1e-05
2022-10-24 11:09:21,061 - INFO] Train Epoch : 09 Loss:	 0.016017	 lr:1e-05
2022-10-24 11:11:01,937 - INFO] Train Epoch : 10 Loss:	 0.014295	 lr:1e-05
2022-10-24 11:12:42,636 - INFO] Train Epoch : 11 Loss:	 0.013444	 lr:1e-05
2022-10-24 11:14:23,305 - INFO] Train Epoch : 12 Loss:	 0.014156	 lr:1e-05
2022-10-24 11:16:03,791 - INFO] Train Epoch : 13 Loss:	 0.014116	 lr:1e-05
2022-10-24 11:17:32,568 - INFO] DVC training
2022-10-24 11:17:32,568 - INFO] config : 
2022-10-24 11:17:32,570 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 11:17:44,795 - INFO] Train Epoch : 14 Loss:	 0.017398	 lr:1e-05
2022-10-24 11:18:42,353 - INFO] global step 5068 : 

2022-10-24 11:18:42,353 - INFO] EWAP_eth dataset : average bpp : 0.105255, average psnr : 36.415431, average msssim: 0.990815

2022-10-24 11:19:25,980 - INFO] Train Epoch : 15 Loss:	 0.013961	 lr:1e-05
2022-10-24 11:21:06,942 - INFO] Train Epoch : 16 Loss:	 0.014562	 lr:1e-05
2022-10-24 11:22:47,870 - INFO] Train Epoch : 17 Loss:	 0.013711	 lr:1e-05
2022-10-24 11:24:28,773 - INFO] Train Epoch : 18 Loss:	 0.015005	 lr:1e-05
2022-10-24 11:26:09,429 - INFO] Train Epoch : 19 Loss:	 0.016654	 lr:1e-05
2022-10-24 11:27:49,672 - INFO] Train Epoch : 20 Loss:	 0.013770	 lr:1e-05
2022-10-24 11:29:30,226 - INFO] Train Epoch : 21 Loss:	 0.014209	 lr:1e-05
2022-10-24 11:31:10,685 - INFO] Train Epoch : 22 Loss:	 0.014085	 lr:1e-05
2022-10-24 11:32:51,250 - INFO] Train Epoch : 23 Loss:	 0.014844	 lr:1e-05
2022-10-24 11:34:31,726 - INFO] Train Epoch : 24 Loss:	 0.014430	 lr:1e-05
2022-10-24 11:36:12,297 - INFO] Train Epoch : 25 Loss:	 0.013875	 lr:1e-05
2022-10-24 11:37:52,882 - INFO] Train Epoch : 26 Loss:	 0.013455	 lr:1e-05
2022-10-24 11:39:34,169 - INFO] Train Epoch : 27 Loss:	 0.014841	 lr:1e-05
2022-10-24 11:41:14,793 - INFO] Train Epoch : 28 Loss:	 0.012921	 lr:1e-05
2022-10-24 11:42:55,332 - INFO] Train Epoch : 29 Loss:	 0.016001	 lr:1e-05
2022-10-24 11:44:35,946 - INFO] Train Epoch : 30 Loss:	 0.016198	 lr:1e-05
2022-10-24 11:46:16,562 - INFO] Train Epoch : 31 Loss:	 0.013965	 lr:1e-05
2022-10-24 11:47:57,244 - INFO] Train Epoch : 32 Loss:	 0.014037	 lr:1e-05
2022-10-24 11:49:37,921 - INFO] Train Epoch : 33 Loss:	 0.013887	 lr:1e-05
2022-10-24 11:51:18,799 - INFO] Train Epoch : 34 Loss:	 0.016302	 lr:1e-05
2022-10-24 11:52:59,683 - INFO] Train Epoch : 35 Loss:	 0.012903	 lr:1e-05
2022-10-24 11:54:40,677 - INFO] Train Epoch : 36 Loss:	 0.012984	 lr:1e-05
2022-10-24 11:56:21,589 - INFO] Train Epoch : 37 Loss:	 0.013510	 lr:1e-05
2022-10-24 11:58:02,536 - INFO] Train Epoch : 38 Loss:	 0.013679	 lr:1e-05
2022-10-24 11:59:43,426 - INFO] Train Epoch : 39 Loss:	 0.018929	 lr:1e-05
2022-10-24 12:01:24,204 - INFO] Train Epoch : 40 Loss:	 0.011372	 lr:1e-05
2022-10-24 12:03:05,188 - INFO] Train Epoch : 41 Loss:	 0.013013	 lr:1e-05
2022-10-24 12:04:45,999 - INFO] Train Epoch : 42 Loss:	 0.015370	 lr:1e-05
2022-10-24 12:06:26,963 - INFO] Train Epoch : 43 Loss:	 0.013837	 lr:1e-05
2022-10-24 12:08:07,673 - INFO] Train Epoch : 44 Loss:	 0.015790	 lr:1e-05
2022-10-24 12:09:48,330 - INFO] Train Epoch : 45 Loss:	 0.014833	 lr:1e-05
2022-10-24 12:11:29,118 - INFO] Train Epoch : 46 Loss:	 0.012466	 lr:1e-05
2022-10-24 12:13:09,513 - INFO] Train Epoch : 47 Loss:	 0.012671	 lr:1e-05
2022-10-24 12:14:50,185 - INFO] Train Epoch : 48 Loss:	 0.015217	 lr:1e-05
2022-10-24 12:16:31,201 - INFO] Train Epoch : 49 Loss:	 0.016015	 lr:1e-05
2022-10-24 12:18:14,426 - INFO] Train Epoch : 50 Loss:	 0.012264	 lr:1e-05
2022-10-24 12:19:55,180 - INFO] Train Epoch : 51 Loss:	 0.012863	 lr:1e-05
2022-10-24 12:21:35,684 - INFO] Train Epoch : 52 Loss:	 0.012929	 lr:1e-05
2022-10-24 12:23:16,241 - INFO] Train Epoch : 53 Loss:	 0.014590	 lr:1e-05
2022-10-24 12:24:57,009 - INFO] Train Epoch : 54 Loss:	 0.014637	 lr:1e-05
2022-10-24 12:26:37,832 - INFO] Train Epoch : 55 Loss:	 0.014497	 lr:1e-05
2022-10-24 14:13:03,961 - INFO] DVC training
2022-10-24 14:13:03,961 - INFO] config : 
2022-10-24 14:13:03,962 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 14:13:30,847 - INFO] DVC training
2022-10-24 14:13:30,848 - INFO] config : 
2022-10-24 14:13:30,849 - INFO] {
    "tot_epoch": 10000,
    "tot_step": 20000,
    "train_lambda": 2048,
    "lr": {
        "base": 0.00001,
        "decay": 0.1,
        "decay_interval": 150000
    }
}

2022-10-24 14:14:38,281 - INFO] global step 20272 : 

2022-10-24 14:14:38,282 - INFO] EWAP_eth dataset : average bpp : 0.100023, average psnr : 36.222059, average msssim: 0.990543

